<!doctype html>



  


<html class="theme-next mist use-motion" lang="en">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>



<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />












  
  
    
  
  <link href="//cdn.jsdelivr.net/fancybox/2.1.5/jquery.fancybox.min.css" rel="stylesheet" type="text/css" />




  
  
  
  

  
    
    
  

  
    
      
    

    
  

  

  
    
      
    

    
  

  
    
      
    

    
  

  
    
    
    <link href="//fonts.googleapis.com/css?family=Monda:300,300italic,400,400italic,700,700italic|Roboto Slab:300,300italic,400,400italic,700,700italic|Lobster Two:300,300italic,400,400italic,700,700italic|consolas:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






  

<link href="//maxcdn.bootstrapcdn.com/font-awesome/4.6.2/css/font-awesome.min.css" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.0" rel="stylesheet" type="text/css" />


  <meta name="keywords" content="NLP," />








  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=5.1.0" />






<meta name="description" content="We firstly show what GloVe is and how it works; then talk about the two way of evaluation of word vectors; and in the end, we discuss the general approach for handling extrinsic tasks.">
<meta property="og:type" content="article">
<meta property="og:title" content="Note of CS224n —— GloVe, Evaluation and Training">
<meta property="og:url" content="http://www.7497.xyz/blog/2020/06/26/notes-of-cs224n-part2.html">
<meta property="og:site_name" content="Near&#39;s Notes">
<meta property="og:description" content="We firstly show what GloVe is and how it works; then talk about the two way of evaluation of word vectors; and in the end, we discuss the general approach for handling extrinsic tasks.">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://p0.ssl.img.360kuai.com/t017141dd916da3881b.webp">
<meta property="article:published_time" content="2020-06-26T14:48:12.000Z">
<meta property="article:modified_time" content="2020-06-27T16:57:34.594Z">
<meta property="article:author" content="Near zeng">
<meta property="article:tag" content="NLP">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://p0.ssl.img.360kuai.com/t017141dd916da3881b.webp">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Mist',
    sidebar: {"position":"right","display":"hide"},
    fancybox: true,
    motion: true,
    duoshuo: {
      userId: 'undefined',
      author: 'Author'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://www.7497.xyz/blog/2020/06/26/notes-of-cs224n-part2.html"/>





<script src="//cdn.bootcss.com/pace/1.0.2/pace.min.js"></script>
<link href="//cdn.bootcss.com/pace/1.0.2/themes/pink/pace-theme-flash.css" rel="stylesheet">
<style>
    .pace .pace-progress {
        background: #1E92FB; /*进度条颜色*/
        height: 3px;
    }
    .pace .pace-progress-inner {
         box-shadow: 0 0 10px #1E92FB, 0 0 5px     #1E92FB; /*阴影颜色*/
    }
    .pace .pace-activity {
        border-top-color: #1E92FB;    /*上边框颜色*/
        border-left-color: #1E92FB;    /*左边框颜色*/
    }
</style>


  <title> Note of CS224n —— GloVe, Evaluation and Training | Near's Notes </title>
<meta name="generator" content="Hexo 4.2.1"></head>

<body itemscope itemtype="http://schema.org/WebPage" lang="en">

  



  <script type="text/javascript">
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?340874ba9357cbe81570aa4ac1185941";
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(hm, s);
    })();
  </script>








  
  
    
  

  <div class="container one-collumn sidebar-position-right page-post-detail ">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-meta custom-logo">
  

  <div class="custom-logo-site-title">
    <a href="/"  class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <span class="site-title">Near's Notes</span>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>
    
      <h1 class="site-subtitle" itemprop="description">NN</h1>
    
</div>

<div class="site-nav-toggle">
  <button>
    <span class="btn-bar"></span>
    <span class="btn-bar"></span>
    <span class="btn-bar"></span>
  </button>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            Home
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            Categories
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            Archives
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            Tags
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br />
            
            About
          </a>
        </li>
      

      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br />
            
            Search
          </a>
        </li>
      
    </ul>
  

  
    <div class="site-search">
      
  <div class="popup">
 <span class="search-icon fa fa-search"></span>
 <input type="text" id="local-search-input">
 <div id="local-search-result"></div>
 <span class="popup-btn-close">close</span>
</div>


    </div>
  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
  <link itemprop="mainEntityOfPage" href="http://www.7497.xyz/blog/2020/06/26/notes-of-cs224n-part2.html">

  <span style="display:none" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <meta itemprop="name" content="Near zeng">
    <meta itemprop="description" content="">
    <meta itemprop="image" content="/images/avatar.gif">
  </span>

  <span style="display:none" itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
    <meta itemprop="name" content="Near's Notes">
    <span style="display:none" itemprop="logo" itemscope itemtype="http://schema.org/ImageObject">
      <img style="display:none;" itemprop="url image" alt="Near's Notes" src="/images/avatar.jpg">
    </span>
  </span>

    
      <header class="post-header">

        
        
          <h2 class="post-title" itemprop="name headline">
            
            
              
                Note of CS224n —— GloVe, Evaluation and Training
              
            
          </h2>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2020-06-26T22:48:12+08:00">
                2020-06-26
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E5%85%A5%E9%97%A8/" itemprop="url" rel="index">
                    <span itemprop="name">入门</span>
                  </a>
                </span>

                
                
                  , 
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E5%85%A5%E9%97%A8/NLP/" itemprop="url" rel="index">
                    <span itemprop="name">NLP</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
		  
			 
          
          
		   
          

		  
            <div class="post-wordcount">
              
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计</span>
                
                <span title="字数统计">
                  528
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长</span>
                
                <span title="阅读时长">
                  3
                </span>
              
            </div>
          
		  
          
              <div class="post-description">
                  We firstly show what GloVe is and how it works; then talk about the two way of evaluation of word vectors; and in the end, we discuss the general approach for handling extrinsic tasks.
              </div>
          
 
        


        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      
        <div class="post-gallery" itemscope itemtype="http://schema.org/ImageGallery">
          
          
            <div class="post-gallery-row">
              <a class="post-gallery-img fancybox"
                 href="https://p0.ssl.img.360kuai.com/t017141dd916da3881b.webp" rel="gallery_ckcxim0nw000j12yn1p020am4"
                 itemscope itemtype="http://schema.org/ImageObject" itemprop="url">
                <img src="https://p0.ssl.img.360kuai.com/t017141dd916da3881b.webp" itemprop="contentUrl"/>
              </a>
            
          

          
          </div>
        </div>
      

      
        <h2 id="1-Global-Vectors-for-Word-Representation-GloVe"><a href="#1-Global-Vectors-for-Word-Representation-GloVe" class="headerlink" title="1. Global Vectors for Word Representation(GloVe)"></a>1. Global Vectors for Word Representation(GloVe)</h2><h3 id="1-1-What’s-GloVe"><a href="#1-1-What’s-GloVe" class="headerlink" title="1.1 What’s GloVe?"></a>1.1 What’s GloVe?</h3><p>GloVe is a word representation tool based on global word frequency (count-based &amp; overall statistics). It can express a word into a vector of real numbers. These vectors some semantic characteristics between words are captured, such as similarity (analogity), analogy (analogy), etc. We can calculate the semantic similarity between two words through operations on vectors, such as Euclidean distance or cosine similarity.</p>
<h3 id="1-2-How-dose-it-work"><a href="#1-2-How-dose-it-work" class="headerlink" title="1.2 How dose it work?"></a>1.2 How dose it work?</h3><h4 id="1-2-1-Construct-a-co-occurrence-matrix"><a href="#1-2-1-Construct-a-co-occurrence-matrix" class="headerlink" title="1.2.1 Construct a co-occurrence matrix"></a>1.2.1 Construct a co-occurrence matrix</h4><p>According to the corpus to build a <a href="http://www.fanyeong.com/2017/10/10/word2vec/" target="_blank" rel="noopener">co-occurrence matrix</a> X, <strong>Each element in the matrix (X_{i,j}) represents the number of times the word (i) and the context word (j) appear together in a context window of a certain size. </strong>Generally speaking, the minimum unit of this number is 1, but GloVe does not think so: it proposes a decay function based on the distance between two words in the context window (d): (decay = 1/d) is used to calculate the weight, that is to say, <strong>the farther away the two words, the smaller the weight of the total count</strong>.</p>
<h4 id="1-2-2-Construct-the-approximate-relationship-between-Word-Vector-and-Co-occurrence-Matrix"><a href="#1-2-2-Construct-the-approximate-relationship-between-Word-Vector-and-Co-occurrence-Matrix" class="headerlink" title="1.2.2 Construct the approximate relationship between Word Vector and Co-occurrence Matrix"></a>1.2.2 Construct the approximate relationship between Word Vector and Co-occurrence Matrix</h4><p>The author of the <a href="https://www.aclweb.org/anthology/D14-1162" target="_blank" rel="noopener">paper</a> proposes the following formula to approximate the relationship between the two:</p>
<script type="math/tex; mode=display">
w_{i}^{T}\tilde{w_{j}} + b_i + \tilde{b_j} = \log(X_{ij}) \tag{1}</script><p>Among them, $(w_{i}^{T})$ and $ ( \tilde{ w_{j} }) $ are the word vectors we finally need to solve; $ (b_i)$  and $ (\tilde{b_j} ) $ Are the bias terms of the two word vectors.<br>Of course, you must have a lot of questions about this formula, such as how did it come from, why should you use this formula, and why should you construct two word vectors $ (w_{i}^{T})$  and $ (\tilde {w_{j}})$ ? We will introduce them in detail below.  </p>
<h4 id="1-2-3-Construct-loss-function"><a href="#1-2-3-Construct-loss-function" class="headerlink" title="1.2.3 Construct loss function"></a>1.2.3 Construct loss function</h4><p>With formula (1), we can construct its loss function:</p>
<script type="math/tex; mode=display">
J = \sum_{i,j=1}^{V} f(X_{ij})(w_{i}^{T}\tilde{w_{j}} + b_i + \tilde{b_j} – \log (X_{ij}) )^2 \tag{2}</script><p>The basic form of this loss function is the simplest mean square loss, but on this basis, a weight function$  (f(X_{ij})) $ is added, then what role does this function play, why should this function be added What? We know that in a corpus, there must be a lot of words that they appear together frequently (frequent co-occurrences), then we hope:</p>
<ol>
<li>The weight of these words is greater than the words that rarely appear together (rare co-occurrences), so if this function is a non-decreasing function (non-decreasing);</li>
<li>But we also don’t want this weight to be overweighted, it should not increase after reaching a certain level;</li>
<li>If the two words do not appear together, that is, $ (X_{ij}=0)$ , then they should not participate in the calculation of the loss function, that is, $ (f(x)) $ must satisfy $ (f(0)=0)$<br>There are many functions that meet the above two conditions, and the author uses the following form of the piecewise function:<script type="math/tex; mode=display">
f(x)=\begin{equation}
\begin{cases}
(x/x_{max})^{\alpha} & \text{if} \ x <x_{max} \\
1 & \text{otherwise}
\end{cases}
\end{equation} \tag{3}</script>The function image is shown below:</li>
</ol>
<p><img src="/blog/2020/06/26/notes-of-cs224n-part2/zE6t1ig.jpg" alt></p>
<p>In all experiments in this paper, the value of $ (\alpha) $ is 0.75, and the value of $ (x_{max})$  is 100. The above is the implementation details of GloVe, so how does GloVe train?</p>
<h4 id="1-2-4-Train-GloVe-Model"><a href="#1-2-4-Train-GloVe-Model" class="headerlink" title="1.2.4 Train GloVe Model"></a>1.2.4 Train GloVe Model</h4><p>Although many people claim that GloVe is an unsupervised learning method (because it does not require manual labeling), it actually has a label. This label is the $ (\log(X_{ in formula (2) ij}))$ , and the vectors $ (w)$  and $ (\tilde{w})$  in formula 2 are the parameters that need to be continuously updated/learned, so in essence its training method is no different from the supervised learning training method Not the same, all based on gradient descent. Specifically, the experiment in this paper is done as follows: AdaGrad’s gradient descent algorithm is used to randomly sample all non-zero elements in the matrix $ (X)$ , and the learning curvature is set to 0.05. If the vector size is less than 300, iterate 50 times, and vectors of other sizes iterate 100 times until convergence. The final learning is that the two vectors are $ (w)$  and $ (\tilde{w})$ , because (X) is symmetric, so in principle $ (w)$  and $ (\tilde{w})$  is also symmetrical, the only difference between them is that the initial values are different, which leads to different final values. So these two are actually equivalent and can be used as the final result. But in order to improve the robustness, we will eventually choose the sum of the two $ (w + \tilde{w})$  as the final vector (different initialization of the two is equivalent to adding different random noise, so it can improve the robustness Sex). After training a corpus of 40 billion tokens, the experimental results obtained are shown below:</p>
<p><img src="/blog/2020/06/26/notes-of-cs224n-part2/X6eVUJJ.jpg" alt></p>
<p>There are three indicators used in this graph: semantic accuracy, grammatical accuracy, and overall accuracy. Then it is not difficult to find that Vector Dimension can achieve the best at 300, and the context Windows size is roughly between 6 and 10.</p>
<h2 id="2-Evaluation-of-Word-Vectors"><a href="#2-Evaluation-of-Word-Vectors" class="headerlink" title="2. Evaluation of Word Vectors"></a>2. Evaluation of Word Vectors</h2><p>In this section, we discuss how we can quantitatively evaluate the quality of word vectors produced by such techniques.</p>
<h3 id="2-1-Intrinsic-Evaluation"><a href="#2-1-Intrinsic-Evaluation" class="headerlink" title="2.1 Intrinsic Evaluation"></a>2.1 Intrinsic Evaluation</h3><p>Intrinsic evaluation of word vectors is the evaluation of a set of word vectors generated by an embedding technique (such as Word2Vec or GloVe) on specific intermediate subtasks (such as analogy completion). These subtasks are typically simple and fast to compute and thereby allow us to help understand the system used to generate the word vectors. An intrinsic evaluation should typically return to us a number that indicates the performance of those word vectors on the evaluation subtask.</p>
<p>Motivation: Let us consider an example where our final goal is to create a question answering system which uses word vectors as inputs. One approach of doing so would be to train a machine learning system that:</p>
<ol>
<li>Takes words as inputs </li>
<li>Converts them to word vectors </li>
<li>Uses word vectors as inputs for an elaborate machine learning system </li>
<li>Maps the output word vectors by this system back to natural language words </li>
<li>Produces words as answers</li>
</ol>
<p>Of course, in the process of making such a state-of-the-art question-answering system, we will need to create optimal word-vector representations since they are used in downstream subsystems (such as deep neural networks). To do this in practice, we will need to tune many hyperparameters in the Word2Vec subsystem (such as the dimension of the word vector representation). While the idealistic approach is to retrain the entire system after any parametric changes in the Word2Vec subsystem, this is impractical from an engineering standpoint because the machine learning system (in step 3) is typically a deep neural network with millions of parameters that takes very long to train. In such a situation, we would want to come up with a simple intrinsic evaluation technique which can provide a measure of “goodness” of the word to word vector subsystem. Obviously, a requirement is that the intrinsic evaluation has a positive correlation with the final task performance.</p>
<h3 id="2-2-Extrinsic-Evaluation"><a href="#2-2-Extrinsic-Evaluation" class="headerlink" title="2.2 Extrinsic Evaluation"></a>2.2 Extrinsic Evaluation</h3><p>Extrinsic evaluation of word vectors is the evaluation of a set of word vectors generated by an embedding technique on the real task at hand. These tasks are typically elaborate and slow to compute. Using our example from above, the system which allows for the evaluation of answers from questions is the extrinsic evaluation system. Typically, optimizing over an underperforming extrinsic evaluation system does not allow us to determine which specific subsystem is at fault and this motivates the need for intrinsic evaluation.</p>
<h3 id="2-3-Summary"><a href="#2-3-Summary" class="headerlink" title="2.3 Summary"></a>2.3 Summary</h3><h5 id="Intrinsic-Evaluation"><a href="#Intrinsic-Evaluation" class="headerlink" title="Intrinsic Evaluation:"></a>Intrinsic Evaluation:</h5><ul>
<li>Evaluate specific intermediate tasks</li>
<li>Faster calculation speed</li>
<li>Help understand the subsystem</li>
<li>Need to be positively correlated with actual tasks to determine usefulness</li>
</ul>
<h5 id="Extrinsic-Evaluation"><a href="#Extrinsic-Evaluation" class="headerlink" title="Extrinsic Evaluation"></a>Extrinsic Evaluation</h5><ul>
<li>an Evaluation of the real task</li>
<li>Computing performance may be slow</li>
<li>It is unclear whether the subsystem is the problem, or other subsystems, or internal interactions</li>
<li>If replacing the subsystem can improve performance, then the change may be good</li>
</ul>
<h2 id="3-Training-for-Extrinsic-Tasks"><a href="#3-Training-for-Extrinsic-Tasks" class="headerlink" title="3. Training for Extrinsic Tasks"></a>3. Training for Extrinsic Tasks</h2><p>We have so far focused on intrinsic tasks and emphasized their importance in developing a good word embedding technique. Of course, the end goal of most real-world problems is to use the resulting word vectors for some other extrinsic task. Here we discuss the general approach for handling extrinsic tasks.</p>
<h3 id="3-1-Problem-Formulation"><a href="#3-1-Problem-Formulation" class="headerlink" title="3.1 Problem Formulation"></a>3.1 Problem Formulation</h3><p>Most NLP extrinsic tasks can be formulated as classification tasks. For instance, given a sentence, we can classify the sentence to have positive, negative or neutral sentiment. Similarly, in named-entity recognition (NER), given a context and a central word, we want to classify the central word to be one of many classes.</p>
<p>In typical machine learning tasks, we usually hold input data and target labels fixed and train weights using optimization techniques (such as gradient descent, L-BFGS, Newton’s method, etc.). In NLP applications however, we introduce the idea of retraining the input word vectors when we train for extrinsic tasks. Let us discuss when and why we should consider doing this.</p>
<h3 id="3-2-Retraining-Word-Vectors"><a href="#3-2-Retraining-Word-Vectors" class="headerlink" title="3.2 Retraining Word Vectors"></a>3.2 Retraining Word Vectors</h3><h3 id="3-3-Softmax-Classification-and-Regularization"><a href="#3-3-Softmax-Classification-and-Regularization" class="headerlink" title="3.3 Softmax Classification and Regularization"></a>3.3 Softmax Classification and Regularization</h3><h3 id="3-4-Window-Classification"><a href="#3-4-Window-Classification" class="headerlink" title="3.4 Window Classification"></a>3.4 Window Classification</h3><h3 id="3-5-Non-linear-Classifiers"><a href="#3-5-Non-linear-Classifiers" class="headerlink" title="3.5 Non-linear Classifiers"></a>3.5 Non-linear Classifiers</h3><h3 id="4-References"><a href="#4-References" class="headerlink" title="4. References"></a>4. References</h3><h5 id="1-GloVe-Global-Vectors-for-Word-Representation"><a href="#1-GloVe-Global-Vectors-for-Word-Representation" class="headerlink" title="1. GloVe: Global Vectors for Word Representation"></a>1. <a href="https://www.aclweb.org/anthology/D14-1162" target="_blank" rel="noopener">GloVe: Global Vectors for Word Representation</a></h5><h5 id="2-GloVe详解"><a href="#2-GloVe详解" class="headerlink" title="2. GloVe详解"></a>2. <a href="http://www.fanyeong.com/2018/02/19/glove-in-detail/" target="_blank" rel="noopener">GloVe详解</a></h5><h5 id="3-cs224n-2019-notes02-wordvecs2"><a href="#3-cs224n-2019-notes02-wordvecs2" class="headerlink" title="3. cs224n-2019-notes02-wordvecs2"></a>3. <a href="https://github.com/datawhalechina/team-learning/tree/master/04%20%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/Lecture/Lecture2/official_notes/cs224n-2019-notes02-wordvecs2.pdf" target="_blank" rel="noopener">cs224n-2019-notes02-wordvecs2</a></h5>
      
    </div>

    <div>
      
        

      
    </div>
  
        <div class="post-tags">
          
            <a href="/tags/NLP/" rel="tag"><i class="fa fa-tag"></i> NLP</a>
          
        </div>
      


    <div>
      
        
  <div style="padding: 10px 0; margin: 20px auto; width: 90%; text-align: center;">
    <div>🐶 您的支持将鼓励我继续创作 🐶</div>
    <button id="rewardButton" disable="enable" onclick="var qr = document.getElementById('QR'); if (qr.style.display === 'none') {qr.style.display='block';} else {qr.style.display='none'}">
      <span>赞赏</span>
    </button>
    <div id="QR" style="display: none;">
      
        <div id="wechat" style="display: inline-block">
          <img id="wechat_qr" src="/images/wechat-reward-img.jpg" alt="Near zeng WeChat Pay"/>
          <p>微信打赏</p>
        </div>
      
      
        <div id="alipay" style="display: inline-block">
          <img id="alipay_qr" src="/images/alipay-reward-img.jpg" alt="Near zeng Alipay"/>
          <p>支付宝打赏</p>
        </div>
      
    </div>
  </div>


      
    </div>


    <footer class="post-footer">
        
     <div>    
      
      <ul class="post-copyright">
         <li class="post-copyright-link">
          <strong>本文作者：</strong>
          <a href="/" title="欢迎访问 Near zeng 的个人博客">Near zeng</a>
        </li>

        <li class="post-copyright-link">
          <strong>本文标题：</strong>
          <a href="http://www.7497.xyz/blog/2020/06/26/notes-of-cs224n-part2.html" title="Note of CS224n —— GloVe, Evaluation and Training">Note of CS224n —— GloVe, Evaluation and Training</a>
        </li>

        <li class="post-copyright-link">
          <strong>本文链接：</strong>
          <a href="http://www.7497.xyz/blog/2020/06/26/notes-of-cs224n-part2.html" title="Note of CS224n —— GloVe, Evaluation and Training">http://www.7497.xyz/blog/2020/06/26/notes-of-cs224n-part2.html</a>
        </li>

        <li class="post-copyright-date">
            <strong>发布时间：</strong>2020年6月26日 - 22时06分
        </li>  

        <li class="post-copyright-license">
          <strong>版权声明： </strong>
          本文由 Near zeng 原创，采用 <a href="https://creativecommons.org/licenses/by-nc-nd/4.0/deed.zh" rel="license" target="_blank">保留署名-非商业性使用-禁止演绎 4.0-国际许可协议</a> </br>转载请保留以上声明信息！
        </li>
      </ul>
    
  </div>  
      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/blog/2020/06/26/exploring-of-word2vec.html" rel="next" title="Exploring of Word2vec">
                <i class="fa fa-chevron-left"></i> Exploring of Word2vec
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/blog/2020/06/29/notes-of-CS224n-part3.html" rel="prev" title="Note of CS224n —— subword">
                Note of CS224n —— subword <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </article>



    <div class="post-spread">
      
    </div>
  </div>

          
          </div>
          


          
  <div class="comments" id="comments">
    
      <div id="lv-container" data-id="city" data-uid="MTAyMC8zMjI4My84ODQ3"></div>
    
  </div>


        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap" >
            Table of Contents
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview">
            Overview
          </li>
        </ul>
      

      <section class="site-overview sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
          <img class="site-author-image" itemprop="image"
               src="/images/avatar.gif"
               alt="Near zeng" />
          <p class="site-author-name" itemprop="name">Near zeng</p>
          <p class="site-description motion-element" itemprop="description">a place for fun</p>
        </div>
        <nav class="site-state motion-element">
        
          
            <div class="site-state-item site-state-posts">
              <a href="/archives">
                <span class="site-state-item-count">13</span>
                <span class="site-state-item-name">posts</span>
              </a>
            </div>
          

          
            <div class="site-state-item site-state-categories">
              <a href="/categories">
                <span class="site-state-item-count">4</span>
                <span class="site-state-item-name">categories</span>
              </a>
            </div>
          

          
            <div class="site-state-item site-state-tags">
              <a href="/tags">
                <span class="site-state-item-count">2</span>
                <span class="site-state-item-name">tags</span>
              </a>
            </div>
          

        </nav>

        

        <div class="links-of-author motion-element">
          
            
              <span class="links-of-author-item">
                <a href="https://github.com/nearzeng" target="_blank" title="GitHub">
                  
                    <i class="fa fa-fw fa-github"></i>
                  
                  GitHub
                </a>
              </span>
            
              <span class="links-of-author-item">
                <a href="https://weibo.com/7333272869/profile?topnav=1&wvr=6&is_all=1" target="_blank" title="weibo">
                  
                    <i class="fa fa-fw fa-weibo"></i>
                  
                  weibo
                </a>
              </span>
            
              <span class="links-of-author-item">
                <a href="https://www.zhihu.com/people/near-63-53" target="_blank" title="zhihu">
                  
                    <i class="fa fa-fw fa-battery-3"></i>
                  
                  zhihu
                </a>
              </span>
            
          
        </div>

        
        

        
        
          <div class="links-of-blogroll motion-element links-of-blogroll-inline">
            <div class="links-of-blogroll-title">
              <i class="fa  fa-fw fa-globe"></i>
              友情链接
            </div>
            <ul class="links-of-blogroll-list">
              
                <li class="links-of-blogroll-item">
                  <a href="https://www.zhihu.com/people/near-63-53" title="友链出租" target="_blank">友链出租</a>
                </li>
              
            </ul>
          </div>
        

        


      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#1-Global-Vectors-for-Word-Representation-GloVe"><span class="nav-number">1.</span> <span class="nav-text">1. Global Vectors for Word Representation(GloVe)</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#1-1-What’s-GloVe"><span class="nav-number">1.1.</span> <span class="nav-text">1.1 What’s GloVe?</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#1-2-How-dose-it-work"><span class="nav-number">1.2.</span> <span class="nav-text">1.2 How dose it work?</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#1-2-1-Construct-a-co-occurrence-matrix"><span class="nav-number">1.2.1.</span> <span class="nav-text">1.2.1 Construct a co-occurrence matrix</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#1-2-2-Construct-the-approximate-relationship-between-Word-Vector-and-Co-occurrence-Matrix"><span class="nav-number">1.2.2.</span> <span class="nav-text">1.2.2 Construct the approximate relationship between Word Vector and Co-occurrence Matrix</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#1-2-3-Construct-loss-function"><span class="nav-number">1.2.3.</span> <span class="nav-text">1.2.3 Construct loss function</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#1-2-4-Train-GloVe-Model"><span class="nav-number">1.2.4.</span> <span class="nav-text">1.2.4 Train GloVe Model</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-Evaluation-of-Word-Vectors"><span class="nav-number">2.</span> <span class="nav-text">2. Evaluation of Word Vectors</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#2-1-Intrinsic-Evaluation"><span class="nav-number">2.1.</span> <span class="nav-text">2.1 Intrinsic Evaluation</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-2-Extrinsic-Evaluation"><span class="nav-number">2.2.</span> <span class="nav-text">2.2 Extrinsic Evaluation</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-3-Summary"><span class="nav-number">2.3.</span> <span class="nav-text">2.3 Summary</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#Intrinsic-Evaluation"><span class="nav-number">2.3.0.1.</span> <span class="nav-text">Intrinsic Evaluation:</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#Extrinsic-Evaluation"><span class="nav-number">2.3.0.2.</span> <span class="nav-text">Extrinsic Evaluation</span></a></li></ol></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#3-Training-for-Extrinsic-Tasks"><span class="nav-number">3.</span> <span class="nav-text">3. Training for Extrinsic Tasks</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#3-1-Problem-Formulation"><span class="nav-number">3.1.</span> <span class="nav-text">3.1 Problem Formulation</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-2-Retraining-Word-Vectors"><span class="nav-number">3.2.</span> <span class="nav-text">3.2 Retraining Word Vectors</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-3-Softmax-Classification-and-Regularization"><span class="nav-number">3.3.</span> <span class="nav-text">3.3 Softmax Classification and Regularization</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-4-Window-Classification"><span class="nav-number">3.4.</span> <span class="nav-text">3.4 Window Classification</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-5-Non-linear-Classifiers"><span class="nav-number">3.5.</span> <span class="nav-text">3.5 Non-linear Classifiers</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4-References"><span class="nav-number">3.6.</span> <span class="nav-text">4. References</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#1-GloVe-Global-Vectors-for-Word-Representation"><span class="nav-number">3.6.0.1.</span> <span class="nav-text">1. GloVe: Global Vectors for Word Representation</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#2-GloVe详解"><span class="nav-number">3.6.0.2.</span> <span class="nav-text">2. GloVe详解</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#3-cs224n-2019-notes02-wordvecs2"><span class="nav-number">3.6.0.3.</span> <span class="nav-text">3. cs224n-2019-notes02-wordvecs2</span></a></li></ol></li></ol></li></ol></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright" >
  
  &copy; 
  <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Near zeng</span>
</div>
<!--

<div class="powered-by">
  Powered by <a class="theme-link" href="https://hexo.io" target="_blank" rel="external nofollow noopener">Hexo</a>
</div>

<div class="theme-info">
  Theme -
  <a class="theme-link" href="https://github.com/iissnan/hexo-theme-next" target="_blank" rel="external nofollow noopener">
    NexT.Mist
  </a>| Hosted by <a href="https://pages.coding.me" target="_blank" rel="noopener" style="font-weight: bold">Coding Pages</a>
</div>

-->




        

        
      </div>
    </footer>

    <div class="back-to-top">
      <i class="fa fa-arrow-up"></i>
    </div>
  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  


  



  
  <script type="text/javascript" src="//cdn.jsdelivr.net/jquery/2.1.3/jquery.min.js"></script>

  
  <script type="text/javascript" src="//cdn.jsdelivr.net/fastclick/1.0.6/fastclick.min.js"></script>

  
  <script type="text/javascript" src="//cdn.jsdelivr.net/jquery.lazyload/1.9.3/jquery.lazyload.min.js"></script>

  
  <script type="text/javascript" src="//cdn.jsdelivr.net/velocity/1.2.3/velocity.min.js"></script>

  
  <script type="text/javascript" src="//cdn.jsdelivr.net/velocity/1.2.3/velocity.ui.min.js"></script>

  
  <script type="text/javascript" src="//cdn.jsdelivr.net/fancybox/2.1.5/jquery.fancybox.pack.js"></script>

  
  <script type="text/javascript" src="/vendors/canvas-nest/canvas-nest.min.js"></script>


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.0"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.0"></script>



  
  

  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.0"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.0"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.0"></script>



  



  




	





  





  

  
      <!-- UY BEGIN -->
      <script type="text/javascript" src="http://v2.uyan.cc/code/uyan.js?uid="></script>
      <!-- UY END -->
  



  
    <script type="text/javascript">
      (function(d, s) {
        var j, e = d.getElementsByTagName(s)[0];
        if (typeof LivereTower === 'function') { return; }
        j = d.createElement(s);
        j.src = 'https://cdn-city.livere.com/js/embed.dist.js';
        j.async = true;
        e.parentNode.insertBefore(j, e);
      })(document, 'script');
    </script>
  


  
  
  <script type="text/javascript">
    // Popup Window;
    var isfetched = false;
    // Search DB path;
    var search_path = "search.xml";
    if (search_path.length == 0) {
      search_path = "search.xml";
    }
    var path = "/" + search_path;
    // monitor main search box;

    function proceedsearch() {
      $("body").append('<div class="popoverlay">').css('overflow', 'hidden');
      $('.popup').toggle();
    }
    // search function;
    var searchFunc = function(path, search_id, content_id) {
      'use strict';
      $.ajax({
        url: path,
        dataType: "xml",
        async: true,
        success: function( xmlResponse ) {
          // get the contents from search data
          isfetched = true;
          $('.popup').detach().appendTo('.header-inner');
          var datas = $( "entry", xmlResponse ).map(function() {
            return {
              title: $( "title", this ).text(),
              content: $("content",this).text(),
              url: $( "url" , this).text()
            };
          }).get();
          var $input = document.getElementById(search_id);
          var $resultContent = document.getElementById(content_id);
          $input.addEventListener('input', function(){
            var matchcounts = 0;
            var str='<ul class=\"search-result-list\">';
            var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
            $resultContent.innerHTML = "";
            if (this.value.trim().length > 1) {
              // perform local searching
              datas.forEach(function(data) {
                var isMatch = false;
                var content_index = [];
                var data_title = data.title.trim().toLowerCase();
                var data_content = data.content.trim().replace(/<[^>]+>/g,"").toLowerCase();
                var data_url = decodeURIComponent(data.url).substring(1);
                var index_title = -1;
                var index_content = -1;
                var first_occur = -1;
                // only match artiles with not empty titles and contents
                if(data_title != '') {
                  keywords.forEach(function(keyword, i) {
                    index_title = data_title.indexOf(keyword);
                    index_content = data_content.indexOf(keyword);
                    if( index_title >= 0 || index_content >= 0 ){
                      isMatch = true;
                      if (i == 0) {
                        first_occur = index_content;
                      }
                    }

                  });
                }
                // show search results
                if (isMatch) {
                  matchcounts += 1;
                  str += "<li><a href='"+ data_url +"' class='search-result-title'>"+ data_title +"</a>";
                  var content = data.content.trim().replace(/<[^>]+>/g,"");
                  if (first_occur >= 0) {
                    // cut out 100 characters
                    var start = first_occur - 20;
                    var end = first_occur + 80;
                    if(start < 0){
                      start = 0;
                    }
                    if(start == 0){
                      end = 50;
                    }
                    if(end > content.length){
                      end = content.length;
                    }
                    var match_content = content.substring(start, end);
                    // highlight all keywords
                    keywords.forEach(function(keyword){
                      var regS = new RegExp(keyword, "gi");
                      match_content = match_content.replace(regS, "<b class=\"search-keyword\">"+keyword+"</b>");
                    });

                    str += "<p class=\"search-result\">" + match_content +"...</p>"
                  }
                  str += "</li>";
                }
              })};
            str += "</ul>";
            if (matchcounts == 0) { str = '<div id="no-result"><i class="fa fa-frown-o fa-5x" /></div>' }
            if (keywords == "") { str = '<div id="no-result"><i class="fa fa-search fa-5x" /></div>' }
            $resultContent.innerHTML = str;
          });
          proceedsearch();
        }
      });}

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched == false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };
    });

    $('.popup-btn-close').click(function(e){
      $('.popup').hide();
      $(".popoverlay").remove();
      $('body').css('overflow', '');
    });
    $('.popup').click(function(e){
      e.stopPropagation();
    });
  </script>


  
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
  


  

  
<script>
(function(){
    var bp = document.createElement('script');
    var curProtocol = window.location.protocol.split(':')[0];
    if (curProtocol === 'https') {
        bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';        
    }
    else {
        bp.src = 'http://push.zhanzhang.baidu.com/push.js';
    }
    var s = document.getElementsByTagName("script")[0];
    s.parentNode.insertBefore(bp, s);
})();
</script>


  

	<!-- 页面点击小红心 
<script type="text/javascript" src="/js/src/love.js"></script>
-->
</body>
</html>
