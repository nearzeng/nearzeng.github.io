<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>零基础入门CV之赛题理解</title>
    <url>//blog/2020/05/22/cv-task1.html</url>
    <content><![CDATA[<h2 id="CV初探"><a href="#CV初探" class="headerlink" title="CV初探"></a>CV初探</h2><h4 id="CV是什么"><a href="#CV是什么" class="headerlink" title="CV是什么"></a>CV是什么</h4><p>计算机视觉（Computational Vision），英文简写CV，是一门“赋予机器自然视觉能力”的学科，是使用计算机模仿人类视觉系统的科学，让计算机拥有类似人类 提取、处理、理解和分析图像以及图像序列的能力。它是一门包含领域很广的综合性学科。从现阶段的研究来看，计算机视觉试图建立一种人工系统，提出的越来越多的理论和技术主要目的是为了从图像或者多维数据中获取信息。</p>
<h4 id="CV可以解决什么问题"><a href="#CV可以解决什么问题" class="headerlink" title="CV可以解决什么问题"></a>CV可以解决什么问题</h4><p>好奇CV可以做什么，是一个比较适用的兴趣点和动力源。一般来说，CV的目标是”看到“。其在具体应用中往往都要解决一些相同的问题，这些问题包括：</p>
<ol>
<li><strong>识别</strong> —— ”看到“图像中的特定目标并能识别出来。</li>
<li><strong>运动</strong> —— ”看到“序列图像中物体的运动和自己在运动，或跟踪运动的物体。</li>
<li><strong>场景重建</strong> —— ”看到“序列图像并建立起完整的三维表面模型。</li>
<li><strong>图像恢复</strong> —— ”看到“一些被影响的部分背后的内容，主要是移除噪声和改善模糊状态</li>
</ol>
<h4 id="CV工程的常见步骤"><a href="#CV工程的常见步骤" class="headerlink" title="CV工程的常见步骤"></a>CV工程的常见步骤</h4><p>简单了解一下工程方面的步骤，有利于知道后续的实践和增加对CV的认识。一般来说，CV工程分为以下5步：</p>
<ol>
<li><strong>图像获取</strong> —— 通过各种图像感知器获取需要的图像数据。</li>
<li><strong>预处理</strong> —— 通过对图像进行一定的预处理来使其满足后续的操作要求。</li>
<li><strong>特征提取</strong> —— 从图像中提取各种复杂度的特征，以便识别目标。</li>
<li><strong>检测/分割</strong> —— 处理过程中，可能需要进一步分割有价值的部分用于后继处理。例如分割出包含特定目标的部分。</li>
<li><strong>高级处理</strong> —— 根据具体应用的需要，验证得到的数据是否符合要求，估测特定的系数等。</li>
</ol>
<h2 id="赛题理解"><a href="#赛题理解" class="headerlink" title="赛题理解"></a>赛题理解</h2><p>通过比赛来实践是一个学习的捷径，在压力之下可能会打破自己原来设定的界限，做到自我突破。当然，对我们这种新手来说，还是要脚踏实地一步一步来的。先来了解下Datawhale与天池联合发起的零基础入门系列赛事第二场 —— <a href="https://tianchi.aliyun.com/competition/entrance/531795/introduction" target="_blank" rel="noopener">零基础入门CV赛事之街景字符识别</a>。</p>
<ul>
<li><strong>赛题名称</strong>：零基础入门CV之街道字符识别            </li>
<li><strong>赛题目标</strong>：通过这道赛题可以引导大家走入计算机视觉的世界，主要针对竞赛选手上手视觉赛题，提高对数据建模能力。       </li>
<li><strong>赛题任务</strong>：赛题以计算机视觉中字符识别为背景，要求选手预测街道字符编码，这是一个典型的字符识别问题。<br>为了简化赛题难度，赛题数据采用公开数据集<a href="http://ufldl.stanford.edu/housenumbers/" target="_blank" rel="noopener">SVHN</a>，因此大家可以选择很多相应的paper作为思路参考。          <h4 id="赛题数据"><a href="#赛题数据" class="headerlink" title="赛题数据"></a>赛题数据</h4></li>
</ul>
<p>赛题以街道字符为赛题数据，数据集报名后可见并可下载，该数据来自公开数据集SVHN收集的街道字符，并进行了匿名采样处理。  </p>
<p><img src="/blog/2020/05/22/cv-task1/数据集样本展示.png" alt="数据示例"></p>
<p><strong>注意: 按照比赛规则，所有的参赛选手只能使用比赛给定的数据集完成训练，不能使用SVHN原始数据集进行训练。比赛结束后将会对Top选手进行代码审核，违规的选手将清除排行榜成绩。</strong></p>
<p>训练集数据包括3W张照片，验证集数据包括1W张照片，每张照片包括颜色图像和对应的编码类别和具体位置；为了保证比赛的公平性，测试集A包括4W张照片，测试集B包括4W张照片。</p>
<p>需要注意的是本赛题需要选手识别图片中所有的字符，为了降低比赛难度，该赛题还提供了训练集、验证集和测试集中所有字符的位置框。</p>
<h4 id="数据标签"><a href="#数据标签" class="headerlink" title="数据标签"></a>数据标签</h4><p>对于训练数据每张图片将给出对应的编码标签和具体的字符框的位置（训练集、测试集和验证集都给出字符位置），可用于模型训练：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">Field</th>
<th style="text-align:center">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">top</td>
<td style="text-align:center">左上角坐标X </td>
</tr>
<tr>
<td style="text-align:center">height</td>
<td style="text-align:center">字符高度 </td>
</tr>
<tr>
<td style="text-align:center">left</td>
<td style="text-align:center">左上角最表Y </td>
</tr>
<tr>
<td style="text-align:center">width</td>
<td style="text-align:center">字符宽度 </td>
</tr>
<tr>
<td style="text-align:center">label</td>
<td style="text-align:center">字符编码 </td>
</tr>
</tbody>
</table>
</div>
<p>字符的坐标具体如下所示：<img src="/blog/2020/05/22/cv-task1/字符坐标.png" alt="坐标">     </p>
<p> 在比赛数据（训练集、测试集和验证集）中，同一张图片中可能包括一个或者多个字符，因此在比赛数据的JSON标注中，会有多个字符的边框信息：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">原始图片</th>
<th style="text-align:center">图片JSON标注</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center"><img src="/blog/2020/05/22/cv-task1/原始图片.png" alt="19"></td>
<td style="text-align:center"><img src="/blog/2020/05/22/cv-task1/原始图片标注.png" alt="标注"></td>
</tr>
</tbody>
</table>
</div>
<h4 id="评测指标"><a href="#评测指标" class="headerlink" title="评测指标"></a>评测指标</h4><p> 选手提交结果与实际图片的编码进行对比，以编码整体识别准确率为评价指标。任何一个字符错误都为错误，最终评测指标结果越大越好，具体计算公式如下：<br>                                              Score = 编码识别正确的数量 / 测试集图片数量        </p>
<h4 id="读取数据"><a href="#读取数据" class="headerlink" title="读取数据"></a>读取数据</h4><p> 这里给出JSON中标签的读取方式：  </p>
 <figure class="highlight python"><table><tr><td class="code"><pre><span class="line"> <span class="keyword">import</span> json</span><br><span class="line">train_json = json.load(open(<span class="string">'../input/train.json'</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 数据标注处理</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">parse_json</span><span class="params">(d)</span>:</span></span><br><span class="line">    arr = np.array([</span><br><span class="line">        d[<span class="string">'top'</span>], d[<span class="string">'height'</span>], d[<span class="string">'left'</span>],  d[<span class="string">'width'</span>], d[<span class="string">'label'</span>]</span><br><span class="line">    ])</span><br><span class="line">    arr = arr.astype(int)</span><br><span class="line">    <span class="keyword">return</span> arr</span><br><span class="line"></span><br><span class="line">img = cv2.imread(<span class="string">'../input/train/000000.png'</span>)</span><br><span class="line">arr = parse_json(train_json[<span class="string">'000000.png'</span>])</span><br><span class="line"></span><br><span class="line">plt.figure(figsize=(<span class="number">10</span>, <span class="number">10</span>))</span><br><span class="line">plt.subplot(<span class="number">1</span>, arr.shape[<span class="number">1</span>]+<span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">plt.imshow(img)</span><br><span class="line">plt.xticks([]); plt.yticks([])</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> idx <span class="keyword">in</span> range(arr.shape[<span class="number">1</span>]):</span><br><span class="line">    plt.subplot(<span class="number">1</span>, arr.shape[<span class="number">1</span>]+<span class="number">1</span>, idx+<span class="number">2</span>)</span><br><span class="line">    plt.imshow(img[arr[<span class="number">0</span>, idx]:arr[<span class="number">0</span>, idx]+arr[<span class="number">1</span>, idx],arr[<span class="number">2</span>, idx]:arr[<span class="number">2</span>, idx]+arr[<span class="number">3</span>, idx]])</span><br><span class="line">    plt.title(arr[<span class="number">4</span>, idx])</span><br><span class="line">    plt.xticks([]); plt.yticks([])</span><br></pre></td></tr></table></figure>
<p><img src="/blog/2020/05/22/cv-task1/19.png" alt="19">     </p>
<h3 id="解题思路"><a href="#解题思路" class="headerlink" title="解题思路"></a>解题思路</h3><p>赛题思路分析：<strong>赛题本质是一个分类识别问题，需要对图片的字符进行识别</strong>。但赛题给定的数据图片中不同图片中包含的字符数量不等。如下图所示，有的图片的字符个数为2，有的图片字符个数为3，有的图片字符个数为4。      </p>
<div class="table-container">
<table>
<thead>
<tr>
<th>字符属性</th>
<th>图片</th>
</tr>
</thead>
<tbody>
<tr>
<td>字符：42   字符个数：2</td>
<td><img src="/blog/2020/05/22/cv-task1/42.png" alt="标注"></td>
</tr>
<tr>
<td>字符：241   字符个数：3</td>
<td><img src="/blog/2020/05/22/cv-task1/2411.png" alt="标注"></td>
</tr>
<tr>
<td>字符：7358   字符个数：4</td>
<td><img src="/blog/2020/05/22/cv-task1/7358.png" alt="标注"></td>
</tr>
</tbody>
</table>
</div>
<p><strong>因此本次赛题的难点是需要对不定长的字符进行识别，与传统的图像分类识别任务有所不同</strong>。</p>
<h4 id="解题思路探索"><a href="#解题思路探索" class="headerlink" title="解题思路探索"></a>解题思路探索</h4><h5 id="Datawhale给出了三种思路："><a href="#Datawhale给出了三种思路：" class="headerlink" title="Datawhale给出了三种思路："></a>Datawhale给出了三种思路：</h5><h5 id="1、简单入门思路：定长字符识别"><a href="#1、简单入门思路：定长字符识别" class="headerlink" title="1、简单入门思路：定长字符识别"></a>1、简单入门思路：定长字符识别</h5><p>可以将赛题抽象为一个定长字符识别问题，在赛题数据集中大部分图像中字符个数为2-4个，最多的字符个数为6个。<br>因此可以对于所有的图像都抽象为6个字符的识别问题，字符23填充为23XXXX，字符231填充为231XXX。    </p>
<p>经过填充之后，原始的赛题可以简化了6个字符的分类问题。在每个字符的分类中会进行11个类别的分类，假如分类为填充字符，则表明该字符为空。可参考Google2014年的论文《Multi-digit Number Recognition from Street View Imagery using Deep Convolutional Neural Networks》，该论文提出了基于深度卷积神经网络的定长字符分类识别方法。</p>
<h5 id="2、专业字符识别思路：不定长字符识别"><a href="#2、专业字符识别思路：不定长字符识别" class="headerlink" title="2、专业字符识别思路：不定长字符识别"></a>2、专业字符识别思路：不定长字符识别</h5><p><img src="/blog/2020/05/22/cv-task1/不定长字符识别.png" alt="标注">      </p>
<p>在字符识别研究中，有特定的方法来解决此种不定长的字符识别问题，比较典型的有CRNN字符识别模型。</p>
<p>CRNN采取的架构是CNN+RNN+CTC，cnn提取图像像素特征，rnn提取图像时序特征，而ctc归纳字符间的连接特性。CRNN能够获取不同尺寸的输入图像，并产生不同长度的预测。它直接在粗粒度的标签（例如单词）上运行，在训练阶段不需要详细标注每一个单独的元素（例如字符）。</p>
<p>此外，<strong>由于CRNN放弃了传统神经网络中使用的全连接层，因此得到了更加紧凑和高效的模型。</strong>所有这些属性使得CRNN成为一种基于图像序列识别的极好方法。</p>
<p>在本次赛题中给定的图像数据都比较规整，可以视为一个单词或者一个句子。   </p>
<h5 id="3、专业分类思路：检测再识别"><a href="#3、专业分类思路：检测再识别" class="headerlink" title="3、专业分类思路：检测再识别"></a>3、专业分类思路：检测再识别</h5><p>在赛题数据中已经给出了训练集、验证集中所有图片中字符的位置，因此可以首先将字符的位置进行识别，利用物体检测的思路完成。        </p>
<p><img src="/blog/2020/05/22/cv-task1/检测.png" alt="IMG">           </p>
<p>此种思路需要参赛选手构建字符检测模型，对测试集中的字符进行识别。选手可以参考物体检测模型SSD或者YOLO来完成。</p>
<p><strong>SSD算法是一种直接预测目标类别和bounding box的多目标检测算法。</strong>与faster rcnn相比，该算法没有生成 proposal 的过程，这就极大提高了检测速度。针对不同大小的目标检测，传统的做法是先将图像转换成不同大小（图像金字塔），然后分别检测，最后将结果综合起来（NMS）。而SSD算法则利用不同卷积层的 <strong>feature map</strong> 进行综合也能达到同样的效果。算法的主网络结构是VGG16，将最后两个全连接层改成卷积层，并随后增加了4个卷积层来构造网络结构。   </p>
<p><strong>YOLO（You Only Look Once: Unified, Real-Time Object Detection）</strong>，是Joseph Redmon和Ali Farhadi等人于2015年提出的基于单个神经网络的目标检测系统。YOLO是一个可以一次性预测多个Box位置和类别的卷积神经网络，能够实现端到端的目标检测和识别，其最大的优势就是速度快。事实上，目标检测的本质就是回归，因此一个实现回归功能的CNN并不需要复杂的设计过程。YOLO没有选择滑动窗口（silding window）或提取proposal的方式训练网络，而是直接选用整图训练模型。这样做的好处在于可以更好的区分目标和背景区域，相比之下，采用proposal训练方式的Fast-R-CNN常常把背景区域误检为特定目标。</p>
<h3 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h3><p>综上所示，本次赛题虽然是一个简单的字符识别问题，但有多种解法可以使用到计算机视觉领域中的各个模型，是非常适合CV入门学习的。解题思路中由浅至深分析了一个分类识别的问题，也是很有参考价值的，也算是给我们这样的初学者指出了一条不断深入和从不同角度分析解决问题的路子。</p>
<h5 id="鸣谢与参考"><a href="#鸣谢与参考" class="headerlink" title="鸣谢与参考"></a>鸣谢与参考</h5><p>References</p>
<ol>
<li><a href="https://github.com/datawhalechina/team-learning/blob/master/03%20%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89%E5%AE%9E%E8%B7%B5%EF%BC%88%E8%A1%97%E6%99%AF%E5%AD%97%E7%AC%A6%E7%BC%96%E7%A0%81%E8%AF%86%E5%88%AB%EF%BC%89/Datawhale%20%E9%9B%B6%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8CV%20-%20Task%2001%20%E8%B5%9B%E9%A2%98%E7%90%86%E8%A7%A3%20.md" target="_blank" rel="noopener">Datawhale 零基础入门CV赛事-Task1 赛题理解</a></li>
<li><a href="https://blog.csdn.net/wsp_1138886114/article/details/82555728?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-2.nonecase&amp;depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-2.nonecase" target="_blank" rel="noopener">CRNN-基于序列的（端到端）图像文本识别</a></li>
<li><a href="https://cloud.tencent.com/developer/article/1064906" target="_blank" rel="noopener">SSD: Single Shot MultiBox Detector 深度学习笔记之SSD物体检测模型</a></li>
<li><a href="https://blog.csdn.net/guoyunfei20/article/details/78744753" target="_blank" rel="noopener">YOLO</a></li>
<li><a href="https://www.cnblogs.com/fariver/p/7446921.html" target="_blank" rel="noopener">YOLO原理</a></li>
<li><a href="https://arxiv.org/pdf/1312.6082.pdf" target="_blank" rel="noopener">Multi-digit Number Recognition from Street View Imagery using Deep Convolutional Neural Networks</a></li>
</ol>
]]></content>
      <categories>
        <category>入门</category>
        <category>天池赛题</category>
      </categories>
      <tags>
        <tag>CV</tag>
      </tags>
  </entry>
  <entry>
    <title>零基础入门CV之数据读取与数据扩增</title>
    <url>//blog/2020/05/23/cv-task2.html</url>
    <content><![CDATA[<h3 id="图像读取"><a href="#图像读取" class="headerlink" title="图像读取"></a>图像读取</h3><p>由于赛题数据是图像数据，赛题的任务是识别图像中的字符。因此我们首先需要完成对数据的读取操作，在Python中有很多库可以完成数据读取的操作，比较常见的有Pillow和OpenCV。     </p>
<h4 id="Pillow"><a href="#Pillow" class="headerlink" title="Pillow"></a>Pillow</h4><p><a href="https://pillow.readthedocs.io/en/stable/" target="_blank" rel="noopener">官方文档</a></p>
<p>Pillow是Python图像处理函式库(PIL）的一个分支。Pillow提供了常见的图像读取和处理的操作，而且可以与ipython notebook无缝集成，是应用比较广泛的库。 </p>
<p>可以简单看下这个库常用的模块：</p>
<p><img src="https://img-blog.csdnimg.cn/20190303145700384.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3N0ZXZlbnRpYW43Mg==,size_16,color_FFFFFF,t_70" alt></p>
<p> <strong>接着我们来演示一下简单其最基本的几个操作</strong>：               <img src="/blog/2020/05/23/cv-task2/2_1.png" alt="原图"></p>
<p><img src="/blog/2020/05/23/cv-task2/2_2.png" alt="rotate"></p>
<p><img src="/blog/2020/05/23/cv-task2/2_3.png" alt="thumbnail"></p>
<p>Pillow还有很多图像操作，是图像处理的必备库。</p>
<h4 id="OpenCV"><a href="#OpenCV" class="headerlink" title="OpenCV"></a>OpenCV</h4><p>OpenCV是一个跨平台的计算机视觉库，最早由Intel开源得来。OpenCV发展的非常早，拥有众多的计算机视觉、数字图像处理和机器视觉等功能。<strong>OpenCV在功能上比Pillow更加强大很多，学习成本也高很多。</strong></p>
<p>我们可以看看OpenCV的学习思维导图：</p>
<p> <img src="https://img-blog.csdn.net/20160812160354901?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center" alt></p>
<p><strong>同样，下面我们演示一些基本的操作：</strong></p>
<p><img src="/blog/2020/05/23/cv-task2/2_4.png" alt></p>
<p><img src="/blog/2020/05/23/cv-task2/2_5.png" alt="gray"></p>
<p><img src="/blog/2020/05/23/cv-task2/2_6.png" alt="canny"></p>
<p>OpenCV包含了众多的图像处理的功能，OpenCV包含了你能想得到的只要与图像相关的操作。此外OpenCV还内置了很多的图像特征处理算法，如关键点检测、边缘检测和直线检测等。<br>OpenCV官网：<a href="https://opencv.org/" target="_blank" rel="noopener">https://opencv.org/</a><br>OpenCV Github：<a href="https://github.com/opencv/opencv" target="_blank" rel="noopener">https://github.com/opencv/opencv</a><br>OpenCV 扩展算法库：<a href="https://github.com/opencv/opencv_contrib" target="_blank" rel="noopener">https://github.com/opencv/opencv_contrib</a></p>
<h3 id="数据扩增方法"><a href="#数据扩增方法" class="headerlink" title="数据扩增方法"></a>数据扩增方法</h3><p>在上一小节中给大家初步介绍了Pillow和OpenCV的使用，现在回到赛题街道字符识别任务中。在赛题中我们需要对的图像进行字符识别，因此需要我们完成的数据的读取操作，同时也需要完成数据扩增（Data Augmentation）操作。     </p>
<h4 id="数据扩增介绍"><a href="#数据扩增介绍" class="headerlink" title="数据扩增介绍"></a>数据扩增介绍</h4><p><strong>在深度学习中数据扩增方法非常重要，数据扩增可以增加训练集的样本，同时也可以有效缓解模型过拟合的情况，也可以给模型带来的更强的泛化能力。</strong></p>
<p><img src="/blog/2020/05/23/cv-task2/数据扩增.png" alt="IMG"></p>
<ul>
<li><h4 id="数据扩增为什么有用？"><a href="#数据扩增为什么有用？" class="headerlink" title="数据扩增为什么有用？"></a>数据扩增为什么有用？</h4>在深度学习模型的训练过程中，数据扩增是必不可少的环节。现有深度学习的参数非常多，一般的模型可训练的参数量基本上都是万到百万级别，而训练集样本的数量很难有这么多。<br>其次数据扩增可以扩展样本空间，假设现在的分类模型需要对汽车进行分类，左边的是汽车A，右边为汽车B。如果不使用任何数据扩增方法，深度学习模型会从汽车车头的角度来进行判别，而不是汽车具体的区别。     </li>
</ul>
<p><img src="/blog/2020/05/23/cv-task2/数据扩增car.png" alt="IMG">   </p>
<ul>
<li><h4 id="有哪些数据扩增方法？"><a href="#有哪些数据扩增方法？" class="headerlink" title="有哪些数据扩增方法？"></a>有哪些数据扩增方法？</h4>数据扩增方法有很多：从颜色空间、尺度空间到样本空间，同时根据不同任务数据扩增都有相应的区别。        <strong>对于图像分类，数据扩增一般不会改变标签；对于物体检测，数据扩增会改变物体坐标位置；对于图像分割，数据扩增会改变像素标签。</strong>      <h4 id="常见的数据扩增方法"><a href="#常见的数据扩增方法" class="headerlink" title="常见的数据扩增方法"></a>常见的数据扩增方法</h4>在常见的数据扩增方法中，一般会从图像颜色、尺寸、形态、空间和像素等角度进行变换。当然不同的数据扩增方法可以自由进行组合，得到更加丰富的数据扩增方法。         </li>
</ul>
<p>以torchvision为例，常见的数据扩增方法包括：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">扩增方法</th>
<th style="text-align:center">功能</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">transforms.CenterCrop</td>
<td style="text-align:center">对图片中心进行裁剪</td>
</tr>
<tr>
<td style="text-align:center">transforms.ColorJitter</td>
<td style="text-align:center">调整图像颜色的对比度、饱和度和零度</td>
</tr>
<tr>
<td style="text-align:center">transforms.FiveCrop</td>
<td style="text-align:center">对图像四个角和中心进行裁剪得到五分图像</td>
</tr>
<tr>
<td style="text-align:center">transforms.Grayscale</td>
<td style="text-align:center">对图像进行灰度变换</td>
</tr>
<tr>
<td style="text-align:center">transforms.Pad</td>
<td style="text-align:center">使用固定值进行像素填充</td>
</tr>
<tr>
<td style="text-align:center">transforms.RandomAffine</td>
<td style="text-align:center">随机仿射变换</td>
</tr>
<tr>
<td style="text-align:center">transforms.RandomCrop</td>
<td style="text-align:center">随机区域裁剪</td>
</tr>
<tr>
<td style="text-align:center">transforms.RandomHorizontalFlip</td>
<td style="text-align:center">随机水平翻转</td>
</tr>
<tr>
<td style="text-align:center">transforms.RandomRotation</td>
<td style="text-align:center">随机旋转</td>
</tr>
<tr>
<td style="text-align:center">transforms.RandomVerticalFlip</td>
<td style="text-align:center">随机垂直翻转</td>
</tr>
</tbody>
</table>
</div>
<p> <img src="/blog/2020/05/23/cv-task2/数据扩增示例.png" alt="IMG">    </p>
<p>在本次赛题中，赛题任务是需要对图像中的字符进行识别，因此对于字符图片并不能进行翻转操作。比如字符6经过水平翻转就变成了字符9，会改变字符原本的含义。    </p>
<h4 id="常用的数据扩增库"><a href="#常用的数据扩增库" class="headerlink" title="常用的数据扩增库"></a>常用的数据扩增库</h4><ul>
<li><h4 id="torchvision"><a href="#torchvision" class="headerlink" title="torchvision"></a><a href="https://github.com/pytorch/vision" target="_blank" rel="noopener">torchvision</a></h4><p>pytorch官方提供的数据扩增库，提供了基本的数据数据扩增方法，可以无缝与torch进行集成；但数据扩增方法种类较少，且速度中等；下面给出的例子就是用这种方法。       </p>
</li>
<li><h4 id="imgaug"><a href="#imgaug" class="headerlink" title="imgaug"></a><a href="https://github.com/aleju/imgaug" target="_blank" rel="noopener">imgaug</a></h4><p>imgaug是常用的第三方数据扩增库，提供了多样的数据扩增方法，且组合起来非常方便，速度较快；      </p>
</li>
<li><h4 id="albumentations"><a href="#albumentations" class="headerlink" title="albumentations"></a><a href="https://albumentations.readthedocs.io" target="_blank" rel="noopener">albumentations</a></h4><p>是常用的第三方数据扩增库，提供了多样的数据扩增方法，对图像分类、语义分割、物体检测和关键点检测都支持，速度较快。      </p>
</li>
</ul>
<h2 id="Pytorch读取数据"><a href="#Pytorch读取数据" class="headerlink" title="Pytorch读取数据"></a>Pytorch读取数据</h2><p>由于本次赛题我们使用Pytorch框架讲解具体的解决方案，接下来将是解决赛题的第一步 —— 使用Pytorch读取赛题数据。<br><strong>在Pytorch中数据是通过Dataset进行封装，并通过DataLoder进行并行读取。</strong></p>
<p>我们先来看一下<strong>Dataset</strong>这个类：</p>
<ol>
<li><strong>作用: 创建数据集，有<code>__getitem__</code>(self, index)函数来根据索引序号获取图片和标签，有<code>__len__</code>(self)函数来获取数据集的长度。</strong></li>
<li><strong>其他的数据集类必须是torch.utils.data.Dataset的子类,比如说torchvision.ImageFolder</strong></li>
</ol>
<p>所以我们只需要重载一下数据读取的逻辑就可以完成数据的读取。      </p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> os, sys, glob, shutil, json</span><br><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch.utils.data.dataset <span class="keyword">import</span> Dataset</span><br><span class="line"><span class="keyword">import</span> torchvision.transforms <span class="keyword">as</span> transforms</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SVHNDataset</span><span class="params">(Dataset)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, img_path, img_label, transform=None)</span>:</span></span><br><span class="line">        self.img_path = img_path</span><br><span class="line">        self.img_label = img_label </span><br><span class="line">        <span class="keyword">if</span> transform <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            self.transform = transform</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            self.transform = <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__getitem__</span><span class="params">(self, index)</span>:</span></span><br><span class="line">        img = Image.open(self.img_path[index]).convert(<span class="string">'RGB'</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> self.transform <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            img = self.transform(img)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 原始SVHN中类别10为数字0</span></span><br><span class="line">        lbl = np.array(self.img_label[index], dtype=np.int)</span><br><span class="line">        lbl = list(lbl)  + (<span class="number">5</span> - len(lbl)) * [<span class="number">10</span>]</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> img, torch.from_numpy(np.array(lbl[:<span class="number">5</span>]))</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__len__</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> len(self.img_path)</span><br><span class="line"></span><br><span class="line">train_path = glob.glob(<span class="string">'../input/train/*.png'</span>)</span><br><span class="line">train_path.sort()</span><br><span class="line">train_json = json.load(open(<span class="string">'../input/train.json'</span>))</span><br><span class="line">train_label = [train_json[x][<span class="string">'label'</span>] <span class="keyword">for</span> x <span class="keyword">in</span> train_json]</span><br><span class="line"></span><br><span class="line">data = SVHNDataset(train_path, train_label,</span><br><span class="line">          transforms.Compose([</span><br><span class="line">              <span class="comment"># 缩放到固定尺寸</span></span><br><span class="line">              transforms.Resize((<span class="number">64</span>, <span class="number">128</span>)),</span><br><span class="line"></span><br><span class="line">              <span class="comment"># 随机颜色变换</span></span><br><span class="line">              transforms.ColorJitter(<span class="number">0.2</span>, <span class="number">0.2</span>, <span class="number">0.2</span>),</span><br><span class="line"></span><br><span class="line">              <span class="comment"># 加入随机旋转</span></span><br><span class="line">              transforms.RandomRotation(<span class="number">5</span>),</span><br><span class="line"></span><br><span class="line">              <span class="comment"># 将图片转换为pytorch 的tesntor</span></span><br><span class="line">              <span class="comment"># transforms.ToTensor(),</span></span><br><span class="line"></span><br><span class="line">              <span class="comment"># 对图像像素进行归一化</span></span><br><span class="line">              <span class="comment"># transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])</span></span><br><span class="line">            ]))</span><br></pre></td></tr></table></figure>
<p>通过上述代码，可以将赛题的图像数据和对应标签进行读取，在读取过程中的进行数据扩增，效果如下所示：</p>
<p>​       </p>
<div class="table-container">
<table>
<thead>
<tr>
<th>1</th>
<th>2</th>
<th>3</th>
</tr>
</thead>
<tbody>
<tr>
<td><img src="/blog/2020/05/23/cv-task2/23.png" alt="IMG"></td>
<td><img src="/blog/2020/05/23/cv-task2/23_1.png" alt="IMG"></td>
<td><img src="/blog/2020/05/23/cv-task2/23_2.png" alt="IMG"></td>
</tr>
<tr>
<td><img src="/blog/2020/05/23/cv-task2/144_1.png" alt="IMG"></td>
<td><img src="/blog/2020/05/23/cv-task2/144_2.png" alt="IMG"></td>
<td><img src="/blog/2020/05/23/cv-task2/144_3.png" alt="IMG"></td>
</tr>
</tbody>
</table>
</div>
<p>接下来我们将在定义好的Dataset基础上构建DataLoder，你可以会问有了Dataset为什么还要有DataLoder？其实这两个是两个不同的概念，是为了实现不同的功能。                 </p>
<ul>
<li><strong>Dataset：对数据集的封装，提供索引方式的对数据样本进行读取</strong>      </li>
<li><strong>DataLoder：对Dataset进行封装，提供批量读取的迭代读取</strong>    </li>
</ul>
<p>其中，<strong>DataLoder</strong>的参数说明如下：</p>
<ul>
<li><code>dataset</code> 传入的数据集；</li>
<li><code>batch_size</code>每个batch有多少个样本；</li>
<li><code>shuffle</code>是否打乱数据；</li>
<li><code>num_workers</code>有几个进程来处理data loading；win下一般不能多进程，只能设置为0；</li>
<li><code>collate_fn</code>将一个list的sample组成一个mini-batch的函数；</li>
</ul>
<p>其主要逻辑处理过程是先通过Dataset类里面的<code>__getitem__</code>函数获取单个的数据，然后组合成batch，再使用<code>collate_fn</code>所指定的函数对这个batch做一些操作，比如padding之类的。</p>
<p> 加入DataLoder后，数据读取代码改为如下：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> os, sys, glob, shutil, json</span><br><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch.utils.data.dataset <span class="keyword">import</span> Dataset</span><br><span class="line"><span class="keyword">import</span> torchvision.transforms <span class="keyword">as</span> transforms</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SVHNDataset</span><span class="params">(Dataset)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, img_path, img_label, transform=None)</span>:</span></span><br><span class="line">        self.img_path = img_path</span><br><span class="line">        self.img_label = img_label </span><br><span class="line">        <span class="keyword">if</span> transform <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            self.transform = transform</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            self.transform = <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__getitem__</span><span class="params">(self, index)</span>:</span></span><br><span class="line">        img = Image.open(self.img_path[index]).convert(<span class="string">'RGB'</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> self.transform <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            img = self.transform(img)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 原始SVHN中类别10为数字0</span></span><br><span class="line">        lbl = np.array(self.img_label[index], dtype=np.int)</span><br><span class="line">        lbl = list(lbl)  + (<span class="number">5</span> - len(lbl)) * [<span class="number">10</span>]</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> img, torch.from_numpy(np.array(lbl[:<span class="number">5</span>]))</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__len__</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> len(self.img_path)</span><br><span class="line"></span><br><span class="line">train_path = glob.glob(<span class="string">'../input/train/*.png'</span>)</span><br><span class="line">train_path.sort()</span><br><span class="line">train_json = json.load(open(<span class="string">'../input/train.json'</span>))</span><br><span class="line">train_label = [train_json[x][<span class="string">'label'</span>] <span class="keyword">for</span> x <span class="keyword">in</span> train_json]</span><br><span class="line"></span><br><span class="line">train_loader = torch.utils.data.DataLoader(</span><br><span class="line">        SVHNDataset(train_path, train_label,</span><br><span class="line">                   transforms.Compose([</span><br><span class="line">                       transforms.Resize((<span class="number">64</span>, <span class="number">128</span>)),</span><br><span class="line">                       transforms.ColorJitter(<span class="number">0.3</span>, <span class="number">0.3</span>, <span class="number">0.2</span>),</span><br><span class="line">                       transforms.RandomRotation(<span class="number">5</span>),</span><br><span class="line">                       transforms.ToTensor(),</span><br><span class="line">                       transforms.Normalize([<span class="number">0.485</span>, <span class="number">0.456</span>, <span class="number">0.406</span>], [<span class="number">0.229</span>, <span class="number">0.224</span>, <span class="number">0.225</span>])</span><br><span class="line">            ])), </span><br><span class="line">    batch_size=<span class="number">10</span>, <span class="comment"># 每批样本个数</span></span><br><span class="line">    shuffle=<span class="literal">False</span>, <span class="comment"># 是否打乱顺序</span></span><br><span class="line">    num_workers=<span class="number">10</span>, <span class="comment"># 读取的线程个数</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> data <span class="keyword">in</span> train_loader:</span><br><span class="line">    <span class="keyword">break</span></span><br></pre></td></tr></table></figure></p>
<p>在加入DataLoder后，数据按照批次获取，每批次调用Dataset读取单个样本进行拼接。此时data的格式为：<br>                <code>torch.Size([10, 3, 64, 128]), torch.Size([10, 6])</code><br>前者为图像文件，为<code>batchsize</code>  <em>  <code>chanel</code>  </em>  <code>height</code>  *  <code>width</code>次序；后者为字符标签。      </p>
<h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>本章对数据读取进行了详细的讲解，并介绍了常见的数据扩增方法和使用，最后使用Pytorch框架对本次赛题的数据进行读取。 </p>
<h5 id="鸣谢和参考"><a href="#鸣谢和参考" class="headerlink" title="鸣谢和参考"></a>鸣谢和参考</h5><p>References</p>
<ol>
<li><a href="https://blog.csdn.net/wfy2695766757/article/details/81193370" target="_blank" rel="noopener">Python的Pillow库进行图像文件处理</a></li>
<li><a href="https://github.com/datawhalechina/team-learning/blob/master/03%20%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89%E5%AE%9E%E8%B7%B5%EF%BC%88%E8%A1%97%E6%99%AF%E5%AD%97%E7%AC%A6%E7%BC%96%E7%A0%81%E8%AF%86%E5%88%AB%EF%BC%89/Datawhale%20%E9%9B%B6%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8CV%20-%20Task%2002%20%E6%95%B0%E6%8D%AE%E8%AF%BB%E5%8F%96%E4%B8%8E%E6%95%B0%E6%8D%AE%E6%89%A9%E5%A2%9E.md" target="_blank" rel="noopener">Datawhale 零基础入门CV赛事-Task2 数据读取与数据扩增</a></li>
<li><a href="https://blog.csdn.net/steventian72/article/details/88088277?utm_medium=distribute.pc_relevant.none-task-blog-baidujs-2" target="_blank" rel="noopener">Python图像处理库PIL的知识点思维导图</a></li>
</ol>
<p>​     </p>
]]></content>
      <categories>
        <category>入门</category>
        <category>天池赛题</category>
      </categories>
      <tags>
        <tag>CV</tag>
      </tags>
  </entry>
  <entry>
    <title>零基础入门CV之CNN初探</title>
    <url>//blog/2020/05/26/cv-task3.html</url>
    <content><![CDATA[<h2 id="CNN-简介"><a href="#CNN-简介" class="headerlink" title="CNN 简介"></a>CNN 简介</h2><h5 id="1、CNN的组成"><a href="#1、CNN的组成" class="headerlink" title="1、CNN的组成"></a>1、CNN的组成</h5><p>CNN由纽约大学的Yann LeCun于1998年提出。本质上是一个多层感知机，其成功的原因关键在于它所采用的局部连接和共享权值的方式。CNN是一类特殊的人工神经网络，是深度学习中重要的一个分支。CNN在很多领域都表现优异，精度和速度比传统计算学习算法高很多。特别是在计算机视觉领域，CNN是解决图像分类、图像检索、物体检测和语义分割的主流模型。CNN通常由卷积（convolution）、池化（pooling）、非线性激活函数（non-linear activation function）和全连接层（fully connected layer）构成。</p>
<p>其中conv层和pooling层简介如下：</p>
<ol>
<li>conv层的理论依据主要是生物学上的感受野概念，通俗点讲就是权值共享，这样可以大大减少神经网络需要训练的参数；卷积核是CNN的重要组成，常见做法是从原始图像中采样，基于无监督学习算法进行训练得到，这一步就是DNN中的预训练。</li>
<li>pooling层，其实就是对图像进行子采样，利用图像局部相关性的原理，在减少数据量的同时又保留有用信息。常见的pooling有max跟mean，就是对每一个采样区域做max运算或者mean运算，既可以减少参数，又可以保留信息，与此同时，还引入平移不变性等图像性质。</li>
</ol>
<h5 id="2、CNN模型的典型结构"><a href="#2、CNN模型的典型结构" class="headerlink" title="2、CNN模型的典型结构"></a>2、CNN模型的典型结构</h5><ol>
<li>LeNet：最早用于数字识别的CNN；</li>
<li>AlexNet：2012年 ILSVRC比赛中远超第二名的CNN，用多层小卷积层替换掉单层大卷积层；</li>
<li>GoogLeNet：2014年 ILSVRC比赛冠军；</li>
<li>VGGNet：2014年表现略差于GoogLeNet，但是在其他图像转换领域表现较好，如目标检测领域；</li>
<li>InceptionV3</li>
<li>ResNet<br><img src="https://upload-images.jianshu.io/upload_images/4070307-d58cba17916ff535.png?imageMogr2/auto-orient/strip|imageView2/2/format/webp" alt="comp"></li>
</ol>
<h2 id="用pytorch构建简单的CNN模型"><a href="#用pytorch构建简单的CNN模型" class="headerlink" title="用pytorch构建简单的CNN模型"></a>用pytorch构建简单的CNN模型</h2><h5 id="1、导入所需包"><a href="#1、导入所需包" class="headerlink" title="1、导入所需包"></a>1、导入所需包</h5><p><img src="/blog/2020/05/26/cv-task3/img1.jpg" alt="tu1"></p>
<h5 id="2、构建一个简单的CNN模型"><a href="#2、构建一个简单的CNN模型" class="headerlink" title="2、构建一个简单的CNN模型"></a>2、构建一个简单的CNN模型</h5><p><img src="/blog/2020/05/26/cv-task3/img4.jpg" alt="tu1"><br><img src="/blog/2020/05/26/cv-task3/img3.jpg" alt="tu1"><br>从<code>print</code>结果可以看出，我们构建了一个由两层卷积层、两层基于max的pool层和两个激活函数构成的简单模型。</p>
<h5 id="3、定义损失函数和优化器"><a href="#3、定义损失函数和优化器" class="headerlink" title="3、定义损失函数和优化器"></a>3、定义损失函数和优化器</h5><p><img src="/blog/2020/05/26/cv-task3/img2.jpg" alt="tu1"><br>我们使用交叉验证损失函数和Adam优化器来训练我们的简单模型。</p>
<h5 id="4、训练网络"><a href="#4、训练网络" class="headerlink" title="4、训练网络"></a>4、训练网络</h5><p><img src="/blog/2020/05/26/cv-task3/img5.jpg" alt="tu1"><br><img src="/blog/2020/05/26/cv-task3/img6.jpg" alt="tu1"></p>
<h3 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h3><p>以上介绍了CNN并用pytorch构建了一个很简单的网络模型，还对该模型进行了必要的分析，以便有一个感性的认识。CNN用处很大，目前了解只是皮毛，还需通过实践来进一步深入的了解和加深实践经验。后续有用到或者有时间再做深入吧。</p>
<h5 id="鸣谢与引用"><a href="#鸣谢与引用" class="headerlink" title="鸣谢与引用"></a>鸣谢与引用</h5><ol>
<li><a href="https://zm.sm-tc.cn/?src=l4uLj4zF0NCdk5CY0ZyMm5HRkZqL0JuNmp6SoJyei5yXmo2gzs%2FQno2LlpyTmtCbmouelpOM0MvIz8%2FOz8rO&amp;uid=2a9b68a44a4de1455fea961a81551e33&amp;hid=884939928472aaaae9ef4cbb2001feec&amp;pos=4&amp;cid=9&amp;time=1590485479485&amp;from=click&amp;restype=1&amp;pagetype=0020004002010402&amp;bu=news_natural&amp;query=CNN%E6%A8%A1%E5%9E%8B&amp;mode=&amp;v=1&amp;force=true&amp;wap=false&amp;province=%E5%B9%BF%E4%B8%9C%E7%9C%81&amp;city=%E5%B9%BF%E5%B7%9E%E5%B8%82&amp;uc_param_str=dnntnwvepffrgibijbprsvdsdichei" target="_blank" rel="noopener">CNN模型</a></li>
<li><a href="https://github.com/datawhalechina/team-learning/blob/master/03%20%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89%E5%AE%9E%E8%B7%B5%EF%BC%88%E8%A1%97%E6%99%AF%E5%AD%97%E7%AC%A6%E7%BC%96%E7%A0%81%E8%AF%86%E5%88%AB%EF%BC%89/Datawhale%20%E9%9B%B6%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8CV%20-%20Task%2003%20%E5%AD%97%E7%AC%A6%E8%AF%86%E5%88%AB%E6%A8%A1%E5%9E%8B.md" target="_blank" rel="noopener">Datawhale 零基础入门CV赛事-Task3 字符识别模型</a></li>
</ol>
]]></content>
      <categories>
        <category>入门</category>
        <category>天池赛题</category>
      </categories>
      <tags>
        <tag>CV</tag>
      </tags>
  </entry>
  <entry>
    <title>零基础入门CV之模型评估与性能度量</title>
    <url>//blog/2020/05/29/cv-task4.html</url>
    <content><![CDATA[<h2 id="模型评估方法"><a href="#模型评估方法" class="headerlink" title="模型评估方法"></a>模型评估方法</h2><p>现实任务中，我们往往有多种学习算法可供选择，甚至对于同一个学习算法，当我们使用不同的参数配置时，也会产生不同的模型。这种情况下，我们选择模型时就得比较和评估，以便我们能选择出泛化性能最好的那个模型。</p>
<p>用学生学习的情况来类比，我们希望学生在一定的课本知识<strong>(训练集)</strong>上学习到某些知识，然后在平时的作业和模拟考<strong>(验证集)</strong>中检查自己学的知识和实际的知识点之间是否有出入，以便最后在期终考试<strong>(测试集、实际应用数据)</strong>有一个比较好的表现——教全面地掌握所要学习的知识。</p>
<p>通过上面这个类比，想必对于大家在机器学习领域常常听说的训练集、验证集和测试集有相对清晰的认识了吧。对我们评估的目标——泛化性能较强这个目标想必也有所理解了。</p>
<h4 id="训练集、验证集和测试集"><a href="#训练集、验证集和测试集" class="headerlink" title="训练集、验证集和测试集"></a>训练集、验证集和测试集</h4><p>我们先来看看为什么要分这三种数据集。在机器学习的过程中，我们的目标是找到那个泛化性能最好的模型，因此我们有两方面的参数需要确定：1、模型里函数的参数，也就是我们常说的权重矩阵w和修正b；这类参数一般在训练过程中通过各种最优化算法求得；2、模型参数，比如多项式回归的次数、规则化参数λ等；这些参数也成为超参数。很明显，为了获得这些参数，我们需要在数据集上训练模型，这就需要一个训练集。为了评估训练出来的模型，以便选择一个效果最好的模型，我们需要一个验证集；为了用上一步选出的最优模型来进行泛化性能评估，我们需要一个测试集。所以，这三个集合的用途分别是：</p>
<ul>
<li><h4 id="训练集（Train-Set）：用于训练模型和调整模型参数-如w、b-；"><a href="#训练集（Train-Set）：用于训练模型和调整模型参数-如w、b-；" class="headerlink" title="训练集（Train Set）：用于训练模型和调整模型参数(如w、b)；"></a>训练集（Train Set）：用于训练模型和调整模型参数(如w、b)；</h4></li>
<li><h4 id="验证集（Validation-Set）：用来验证模型精度和确定模型超参数，以便选出最优模型；"><a href="#验证集（Validation-Set）：用来验证模型精度和确定模型超参数，以便选出最优模型；" class="headerlink" title="验证集（Validation Set）：用来验证模型精度和确定模型超参数，以便选出最优模型；"></a>验证集（Validation Set）：用来验证模型精度和确定模型超参数，以便选出最优模型；</h4></li>
<li><h4 id="测试集（Test-Set）：仅用于对最优模型进行性能评估，验证模型的泛化能力。"><a href="#测试集（Test-Set）：仅用于对最优模型进行性能评估，验证模型的泛化能力。" class="headerlink" title="测试集（Test Set）：仅用于对最优模型进行性能评估，验证模型的泛化能力。"></a>测试集（Test Set）：仅用于对最优模型进行性能评估，验证模型的泛化能力。</h4></li>
</ul>
<p>一般来说，我们拿到的都只有一个数据集D，那如何对D进行适当的处理，以便从中产生出训练集S、验证集V和测试集T呢？常用的方法有一下三种：</p>
<h5 id="1、留出法（Hold-Out）"><a href="#1、留出法（Hold-Out）" class="headerlink" title="1、留出法（Hold-Out）"></a>1、留出法（Hold-Out）</h5><p>直接将数据集D划分成两个互斥的部分——训练集S和验证集T。一般来说是把其中的2/3~4/5划为训练集，其余为验证集；与此同时，为了保证划分的集合分布与原集合分布一致，通常使用“分层采样”的方式划分。这种划分方式的优点是最为直接简单，缺点是只得到了一份验证集，有可能导致模型在验证集上过拟合。因此，留出法应用场景一般是数据量比较大的情况。</p>
<h5 id="2、交叉验证法（Cross-Validation，CV）"><a href="#2、交叉验证法（Cross-Validation，CV）" class="headerlink" title="2、交叉验证法（Cross Validation，CV）"></a>2、交叉验证法（Cross Validation，CV）</h5><p>将训练集划分成K份，将其中的K-1份作为训练集，剩余的1份作为验证集，循环K训练。也就是K折交叉验证。如果K=1，则叫留一法。这种划分方式是所有的训练集都是验证集，最终模型验证精度是K份平均得到。优点是验证集精度比较可靠，训练K次可以得到K个有多样性差异的模型；C缺点是需要训练K次，导致复杂度过大，不适合数据量很大的情况。</p>
<h5 id="3、自助采样法（BootStrap）"><a href="#3、自助采样法（BootStrap）" class="headerlink" title="3、自助采样法（BootStrap）"></a>3、自助采样法（BootStrap）</h5><p>这种方法我是通过吃自助餐理解的，就是一种数据自助取用的方式。通过有放回的采样方式得到新的训练集和验证集，每次的训练集和验证集都是有区别的。通过概率计算可以知道，大概有2/3左右的数据会被采样到训练集，而有1/3是没有在训练集出现的。这种划分方式一般适用于数据量较小，难以有效划分的情况。此外，自助法能从初始数据集中产生出多个不同的训练集，对于集成学习来说是有利的。缺点是采样过程中一定程度上改变了初始数据集的分布，也就是引入了估计偏差。因此，一般来说用前面两种方法比较多。</p>
<h2 id="模型性能度量"><a href="#模型性能度量" class="headerlink" title="模型性能度量"></a>模型性能度量</h2><p>对模型的泛化性能进行评估，不仅仅需要有效可行的实验估计方法，还需要有衡量模型泛化能力的评价标准，这就是性能度量(performance measure)。</p>
<p>一般来说，性能度量是反映任务需求的。就是说，我们要实事求是，不同类型的任务使用不同的性能度量，好的模型不仅取决于算法和数据，还取决于任务需求。</p>
<h4 id="回归任务的评估"><a href="#回归任务的评估" class="headerlink" title="回归任务的评估"></a>回归任务的评估</h4><p><img src="/blog/2020/05/29/cv-task4/tu1.png" alt></p>
<h4 id="分类任务的评估"><a href="#分类任务的评估" class="headerlink" title="分类任务的评估"></a>分类任务的评估</h4><p><strong>使用混淆矩阵评估模型</strong>:</p>
<p><img src="/blog/2020/05/29/cv-task4/tu4.png" alt></p>
<h4 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h4><p>本文简要梳理了机器学习中常见的三种数据集类别：训练集、验证集和测试集；并对常见的三种数据集划分方式做了介绍。最后提了一下模型的性能度量，了解还不够深入，留以后再做补充。</p>
<h3 id="References"><a href="#References" class="headerlink" title="References"></a>References</h3><ol>
<li>《机器学习》. 周志华</li>
<li><a href="http://stats.stackexchange.com/questions/52274/how-to-choose-a-predictive-model-after-k-fold-cross-validation" target="_blank" rel="noopener">How to choose a predictive model after k-fold cross-validation</a></li>
<li><a href="https://www.jianshu.com/p/21cb3ad928c6" target="_blank" rel="noopener">模型性能度量方法</a></li>
</ol>
]]></content>
      <categories>
        <category>入门</category>
        <category>天池赛题</category>
      </categories>
      <tags>
        <tag>CV</tag>
      </tags>
  </entry>
  <entry>
    <title>零基础入门CV之集成学习</title>
    <url>//blog/2020/06/02/cv-task5.html</url>
    <content><![CDATA[<h2 id="集成学习是什么"><a href="#集成学习是什么" class="headerlink" title="集成学习是什么"></a>集成学习是什么</h2><h2 id="一、集成学习是什么"><a href="#一、集成学习是什么" class="headerlink" title="一、集成学习是什么"></a>一、集成学习是什么</h2><p>“团结就是力量”、“综合就是全面”，这是机器学习领域中”集成学习“的基本思想。大多数数据竞赛排名靠前的解决方案所采用的集成方法，都建立在一个假设：组合多个模型以期得到一个更全面的模型，从而得到一个泛化性能更好的模型。</p>
<p>集成学习一般有Bagging、Boosting和Stacking三种类别：</p>
<ul>
<li><strong>Bagging</strong>：利用bootstrap方法从整体数据集中采取有放回抽样得到N个数据集，在每个数据集上学习出一个模型，最后的预测结果利用N个模型的输出综合得到。具体地：分类问题采用N个模型预测投票的方式，回归问题采用N个模型预测平均的方式。</li>
<li><strong>Boosting</strong>：一种可以用来减小监督学习中偏差的机器学习算法。主要也是学习一系列弱分类器，并将其组合为一个强分类器。</li>
<li><strong>Stacking</strong>：指训练一个模型用于组合其他各个模型。首先我们先训练多个不同的模型，然后把之前训练的各个模型的输出为输入来训练一个模型，以得到一个最终的输出。</li>
</ul>
<h2 id="二、集成学习的应用场景"><a href="#二、集成学习的应用场景" class="headerlink" title="二、集成学习的应用场景"></a>二、集成学习的应用场景</h2><p>集成学习的主要应用场景有以下几个方面：</p>
<ol>
<li><strong>模型选择</strong>：相比于只选择一个模型，集成学习对模型集合中所有模型的输出按照某种方法进行组合，例如简单的取平均，可以降低模型选择不当的风险。这个要求能达到适当的多样性，这样才能通过一定的策略优势互补地减少总体误差。</li>
<li><strong>分而治之</strong>：集成学习系统遵循一种分而治之的方法，将数据空间划分为更小、更易于学习的分区，其中每个模型只学习其中一个更简单的分区。然后通过不同方法来适当组合模型的输出来近似复杂决策边界。这可以解决难以用一个模型来处理的机器学习问题。</li>
<li><strong>数据融合</strong>：在许多需要自动决策的应用程序中，接收来自不同来源的数据并提供补充信息是很常见的。这种信息的适当组合被称为<strong>数据或信息融合</strong>，与仅根据任何单个数据源进行决策相比，可以提高分类决策的准确性。</li>
<li><strong>置信度估计</strong>：考虑对一个分类问题训练一个分类器集合，如果集合中绝大多数分类器决策一致，那么就认为整体决策的结果具有较高置信度；反之则具有较低置信度。</li>
<li><strong>数据扩增</strong>：如果训练数据量太小，那么使用bootstrapping技术可以从总体数据集中有放回的随机采样获得多个样本集，每个样本集作为训练集训练一个模型，最后再以一定策略组合。</li>
</ol>
<h2 id="三、集成学习的结合策略"><a href="#三、集成学习的结合策略" class="headerlink" title="三、集成学习的结合策略"></a>三、集成学习的结合策略</h2><p>模型集合的组合方法有很多，我们这里主要介绍在实践中最常用的四种：线性组合、乘积组合、投票组合和学习组合。</p>
<ol>
<li><strong>线性组合</strong>：线性组合用于输出实数的模型，因此适用于回归模型结果的集成，或分类模型集成中估计类别的概率。</li>
<li><strong>乘积组合</strong>：在各模型的类别条件概率估计相互独立的假设下，乘积组合在理论上是最好的组合策略。</li>
<li><strong>投票组合</strong>：每个分类器对某个类别投票，获得多数票的类别作为集成模型整体的输出。包括相对多数投票法、绝对多数投票法和加权投票法。</li>
<li><strong>学习组合</strong>：通过机器学习的方式来组合，代表是Stacking。我们将弱学习器称为初级学习器，将用于结合的学习器称为次级学习器。对于测试集，我们首先用初级学习器预测一次，得到次级学习器的输入样本，再用次级学习器预测一次，得到最终的预测结果。</li>
</ol>
<h2 id="References"><a href="#References" class="headerlink" title="References"></a>References</h2><ol>
<li><a href="https://www.jianshu.com/p/3e8c44314be5" target="_blank" rel="noopener">集成学习(Ensemble learning)</a></li>
<li><a href="https://www.cnblogs.com/wxquare/p/5440664.html" target="_blank" rel="noopener">集成学习方法</a></li>
</ol>
]]></content>
      <categories>
        <category>入门</category>
        <category>天池赛题</category>
      </categories>
      <tags>
        <tag>CV</tag>
      </tags>
  </entry>
  <entry>
    <title>Note of CS224N Lecture1 —— Introduction and word vectors</title>
    <url>//blog/2020/06/24/notes-of-CS224n-part1.html</url>
    <content><![CDATA[<h1 id="Note-of-CS224N-Lecture1-Introduction-and-word-vectors"><a href="#Note-of-CS224N-Lecture1-Introduction-and-word-vectors" class="headerlink" title="Note of CS224N Lecture1: Introduction and word vectors"></a>Note of CS224N Lecture1: Introduction and word vectors</h1><blockquote>
<p>School:  Stanford</p>
<p>Teacher: Prof. Christopher Manning</p>
<p>Library: Pytorch</p>
<p>Course: <a href="https://web.stanford.edu/class/archive/cs/cs224n/cs224n.1194/index.html" target="_blank" rel="noopener">CS224n</a></p>
</blockquote>
<h2 id="1-What’s-NLP"><a href="#1-What’s-NLP" class="headerlink" title="1. What’s NLP?"></a>1. What’s NLP?</h2><h4 id="a-Definition"><a href="#a-Definition" class="headerlink" title="a. Definition"></a>a. Definition</h4><p>Natural Language Processing(NLP for short),  is broadly defined as the automatic manipulation of natural language which refers to the way we humans communicate with each other, like speech and text, by software. </p>
<h4 id="b-Basic-tasks"><a href="#b-Basic-tasks" class="headerlink" title="b. Basic tasks"></a>b. Basic tasks</h4><p>The study of NLP has been around for more than half a century, and the target of NLP is helping computers understand, interpret and manipulate human language, which isn’t really solved. </p>
<p>NLP includes many different techniques for interpreting human language, ranging from statistical and machine learning methods to rules-based and algorithmic approaches. We need a broad array of approaches because the text- and voice-based data varies widely, as do the practical applications. </p>
<p>Basic NLP tasks include tokenization and parsing, lemmatization/stemming, part-of-speech tagging, language detection and identification of semantic relationships. If you ever diagramed sentences in grade school, you’ve done these tasks manually before. </p>
<p>In general terms, NLP tasks break down language into shorter, elemental pieces, try to understand relationships between the pieces and explore how the pieces work together to create meaning.</p>
<h5 id="1-Content-categorization"><a href="#1-Content-categorization" class="headerlink" title="1. Content categorization"></a>1. Content categorization</h5><h5 id="2-Topic-discovery-and-modeling"><a href="#2-Topic-discovery-and-modeling" class="headerlink" title="2. Topic discovery and modeling"></a>2. Topic discovery and modeling</h5><h5 id="3-Contextual-extraction"><a href="#3-Contextual-extraction" class="headerlink" title="3. Contextual extraction"></a>3. Contextual extraction</h5><h5 id="4-Sentiment-analysis"><a href="#4-Sentiment-analysis" class="headerlink" title="4. Sentiment analysis"></a>4. Sentiment analysis</h5><h5 id="5-Speech-to-text-and-text-to-speech-conversion"><a href="#5-Speech-to-text-and-text-to-speech-conversion" class="headerlink" title="5. Speech-to-text and text-to-speech conversion"></a>5. Speech-to-text and text-to-speech conversion</h5><h5 id="6-Document-summarization"><a href="#6-Document-summarization" class="headerlink" title="6. Document summarization"></a>6. Document summarization</h5><h5 id="7-Machine-translation"><a href="#7-Machine-translation" class="headerlink" title="7. Machine translation"></a>7. Machine translation</h5><h2 id="2-What’s-word-vectors"><a href="#2-What’s-word-vectors" class="headerlink" title="2. What’s word vectors?"></a>2. What’s word vectors?</h2><p><img src="/blog/2020/06/24/notes-of-CS224n-part1/word_vectors.png" alt></p>
<p>Obviously, the first step of all NLP tasks is how we represent words as input to any our models. Word vectors which are the texts converted into numbers and there may be different numerical representations of the same text, give a way to this problem. </p>
<p>A Word vector format generally tries to map a word using a dictionary to a vector. Let us break this phrase down into finer details to have a clear view.</p>
<p>Take a look at this example - “The banking system is a basic system”; A dictionary may be the list of all unique words in the sentence. So, a dictionary may look like – [‘The’,’banking’,’system’,’is’,’a’,’basic’]. A vector representation of a word may be a one-hot encoded vector, like a vector show in above picture.</p>
<h5 id="Different-types-of-Word-Vectors"><a href="#Different-types-of-Word-Vectors" class="headerlink" title="Different types of Word Vectors"></a>Different types of Word Vectors</h5><p>The different types of word vectors can be broadly classified into two categories-</p>
<ol>
<li>Frequency based</li>
<li>Prediction based</li>
</ol>
<h5 id="Word2vec"><a href="#Word2vec" class="headerlink" title="Word2vec"></a>Word2vec</h5><p><img src="/blog/2020/06/24/notes-of-CS224n-part1/word2vec.png" alt></p>
<h2 id="3-What’s-next"><a href="#3-What’s-next" class="headerlink" title="3. What’s next?"></a>3. What’s next?</h2><p>I joined in a NLP learning activity held by an open-source organization <a href="https://datawhale.club/" target="_blank" rel="noopener">Datawhale</a> recently. We are gonna learning the awesome course <a href="https://web.stanford.edu/class/archive/cs/cs224n/cs224n.1194/index.html" target="_blank" rel="noopener">CS224n</a> by Stanford in this activity. </p>
<p>I will keep updating my progress and my learning note in the upcoming posts on this blog. As a beginner of this field, I have a lot to learn. I may just follow the plan of this activity or this course to have a big picture of NLP. So, my next post may be the exploring of Word2vec.</p>
<h2 id="References"><a href="#References" class="headerlink" title="References"></a>References</h2><ol>
<li><p><a href="https://www.sas.com/en_us/insights/analytics/what-is-natural-language-processing-nlp.html#howitworks" target="_blank" rel="noopener">NLP: What it is and why it matters</a></p>
</li>
<li><p><a href="https://www.analyticsvidhya.com/blog/2017/06/word-embeddings-count-word2veec/" target="_blank" rel="noopener">An Intuitive Understanding of Word Embeddings: From Count Vectors to Word2Vec</a></p>
</li>
</ol>
]]></content>
      <categories>
        <category>入门</category>
        <category>NLP</category>
      </categories>
      <tags>
        <tag>NLP</tag>
      </tags>
  </entry>
  <entry>
    <title>Exploring of Word2vec</title>
    <url>//blog/2020/06/26/exploring-of-word2vec.html</url>
    <content><![CDATA[<blockquote>
<p>Word2vec is a deep learning technique that feeds massive amounts of text into a shallow neural net which can then be used to solve a variety of NLP and ML problems. Usually, Word2vec Explorer uses <a href="https://github.com/piskvorky/gensim" target="_blank" rel="noopener">Gensim</a> to list and compare vectors. </p>
</blockquote>
<h2 id="1-recommented-refs-of-Word2vec"><a href="#1-recommented-refs-of-Word2vec" class="headerlink" title="1. recommented refs of Word2vec"></a>1. recommented refs of Word2vec</h2><ol>
<li>Mikolov’s papers:<ol>
<li><a href="https://arxiv.org/pdf/1405.4053.pdf" target="_blank" rel="noopener">Distributed Representations of Sentences and Documents</a> Word2vec, a more powerful language model framework, is proposed and used to generate word vectors.</li>
<li><a href="https://arxiv.org/pdf/1301.3781.pdf" target="_blank" rel="noopener">Efficient estimation of word representations in vector space</a> mainly about two tricks of word2vec: hierarchical softmax, negative sampling.</li>
</ol>
</li>
<li>Yoav Goldberg’s paper: <a href="https://arxiv.org/pdf/1402.3722.pdf" target="_blank" rel="noopener">word2vec Explained: deriving Mikolov et al.’s negative-sampling word-embedding method</a> good for learning more about the formula of negative sampling.</li>
<li>Xin Rong’s paper: <a href="https://arxiv.org/pdf/1411.2738.pdf" target="_blank" rel="noopener">word2vec Parameter Learning Explained</a> highly recommented! There are both high-level intuition explanations and detailed derivation processes.</li>
<li>Siwei lai’s paper: <a href="https://arxiv.org/ftp/arxiv/papers/1611/1611.05962.pdf" target="_blank" rel="noopener">Word and Document Embeddings based on Neural Network Approaches</a> </li>
</ol>
<h2 id="2-Word2vec"><a href="#2-Word2vec" class="headerlink" title="2. Word2vec"></a>2. Word2vec</h2><h3 id="2-1-what’s-Word2vec？"><a href="#2-1-what’s-Word2vec？" class="headerlink" title="2.1 what’s Word2vec？"></a>2.1 what’s Word2vec？</h3><p>To perform NLP, we need to find a way to vectorise words so that we can input them into our machine. So we need word embedding, which can convert symbolic words into numerical forms, in other word, embedded into a mathematical space. And Word2vec is a kind of word embedding. </p>
<p>Word2vec only care about the model parameters (specifically the weight of the neural network), and take these parameters as a kind of vectorized representation of the input word. That means we can use Word2vec to generate word vectors.</p>
<h3 id="2-2-Skip-gram-and-CBOW"><a href="#2-2-Skip-gram-and-CBOW" class="headerlink" title="2.2 Skip-gram and CBOW"></a>2.2 Skip-gram and CBOW</h3><ul>
<li><strong>Skip-gram</strong>: a model use a word as input to predict the context around it.</li>
<li><strong>CBOW</strong>: a model use the context around a word as input to predict the word itself.</li>
</ul>
<h4 id="2-2-1-Skip-gram"><a href="#2-2-1-Skip-gram" class="headerlink" title="2.2.1 Skip-gram"></a>2.2.1 Skip-gram</h4><p>we can take a look at the Skip-gram network structure:</p>
<p><img src="/blog/2020/06/26/exploring-of-word2vec/vec.jpg" alt></p>
<p>which x is one-hot encoder which is a vector only containing one one and all other zeros and used to uniquely represent a word; y is the probability of these V words output as a group.</p>
<p>Let’s notice this: <strong>the activation function of the hidden layer is actually linear</strong>, which the key method of Word2vec simplify the previous language model. And we use BP to train this neural network. After training, we got the weights of this net. Because only the weight corresponding to the different position of 1’s is activated, this Vx which is consisted of the weights we got can be used to uniquely represent x.  And the dimension of Vx is generally far smaller than the total number of words V, so Word2vec is essentially a dimensionality reduction operation.</p>
<p>while y has multiple words, the network structure is as follows:</p>
<p><img src="/blog/2020/06/26/exploring-of-word2vec/vet2.jpg" alt></p>
<p>It can be seen as a parallel of a single x-&gt;single y model, and the cost function is the accumulation of a single cost function (after taking log). </p>
<h4 id="2-2-2-CBOW"><a href="#2-2-2-CBOW" class="headerlink" title="2.2.2 CBOW"></a>2.2.2 CBOW</h4><p>Similar to Skip-gram, except Skip-gram predicts the context of a word, and CBOW predicts the word using context.</p>
<p>Network structure is as follow:</p>
<p><img src="/blog/2020/06/26/exploring-of-word2vec/cbow.jpg" alt></p>
<p>It is different from the Skip-gram model in parallel. Here, the input becomes multiple words, so we need to process the input (generally sum and then average) first. The cost function of the output is unchanged. For detail you can read this paper: <a href="https://arxiv.org/pdf/1411.2738.pdf" target="_blank" rel="noopener">word2vec Parameter Learning Explained</a>.</p>
<h3 id="2-3-training-tricks"><a href="#2-3-training-tricks" class="headerlink" title="2.3 training tricks"></a>2.3 training tricks</h3><p>Why do we need training tricks? As we just mentioned, Word2vec is essentially a language model, its output node number is V, corresponding to V words, which is essentially a multi-classification problem. But in reality, the number of words is very, very large. It will cause great difficulty in calculation, so we need to use tricks to accelerate the training.</p>
<p>Here are two tricks:</p>
<ul>
<li><p>hierarchical softmax: turn the N classification problem into log(N) secondary classification.</p>
</li>
<li><p>negative sampling: predict a subset of the overall category.</p>
</li>
</ul>
<h2 id="3-References"><a href="#3-References" class="headerlink" title="3. References"></a>3. References</h2><h5 id="1-Natural-Language-Processing1-Word-To-Vectors"><a href="#1-Natural-Language-Processing1-Word-To-Vectors" class="headerlink" title="1. Natural Language Processing1: Word To Vectors"></a>1. <a href="https://billmazengou.github.io/2020/06/23/NLP1-Word-to-Vectors/" target="_blank" rel="noopener">Natural Language Processing1: Word To Vectors</a></h5><h5 id="2-Word2Vec-Explorer"><a href="#2-Word2Vec-Explorer" class="headerlink" title="2. Word2Vec Explorer"></a>2. <a href="https://github.com/dominiek/word2vec-explorer" target="_blank" rel="noopener">Word2Vec Explorer</a></h5><h5 id="3-Distributed-Representations-of-Sentences-and-Documents"><a href="#3-Distributed-Representations-of-Sentences-and-Documents" class="headerlink" title="3. Distributed Representations of Sentences and Documents"></a>3. <a href="https://arxiv.org/pdf/1405.4053.pdf" target="_blank" rel="noopener">Distributed Representations of Sentences and Documents</a></h5><h5 id="4-Efficient-estimation-of-word-representations-in-vector-space"><a href="#4-Efficient-estimation-of-word-representations-in-vector-space" class="headerlink" title="4. Efficient estimation of word representations in vector space"></a>4. <a href="https://arxiv.org/pdf/1301.3781.pdf" target="_blank" rel="noopener">Efficient estimation of word representations in vector space</a></h5><h5 id="5-word2vec-Explained-deriving-Mikolov-et-al-’s-negative-sampling-word-embedding-method"><a href="#5-word2vec-Explained-deriving-Mikolov-et-al-’s-negative-sampling-word-embedding-method" class="headerlink" title="5.  word2vec Explained: deriving Mikolov et al.’s negative-sampling word-embedding method"></a>5.  <a href="https://arxiv.org/pdf/1402.3722.pdf" target="_blank" rel="noopener">word2vec Explained: deriving Mikolov et al.’s negative-sampling word-embedding method</a></h5><h5 id="6-word2vec-Parameter-Learning-Explained"><a href="#6-word2vec-Parameter-Learning-Explained" class="headerlink" title="6. word2vec Parameter Learning Explained"></a>6. <a href="https://arxiv.org/pdf/1411.2738.pdf" target="_blank" rel="noopener">word2vec Parameter Learning Explained</a></h5><h5 id="7-Word-and-Document-Embeddings-based-on-Neural-Network-Approaches"><a href="#7-Word-and-Document-Embeddings-based-on-Neural-Network-Approaches" class="headerlink" title="7.  Word and Document Embeddings based on Neural Network Approaches"></a>7.  <a href="https://arxiv.org/ftp/arxiv/papers/1611/1611.05962.pdf" target="_blank" rel="noopener">Word and Document Embeddings based on Neural Network Approaches</a></h5>]]></content>
      <categories>
        <category>入门</category>
        <category>NLP</category>
      </categories>
      <tags>
        <tag>NLP</tag>
      </tags>
  </entry>
  <entry>
    <title>Note of CS224n —— GloVe, Evaluation and Training</title>
    <url>//blog/2020/06/26/notes-of-cs224n-part2.html</url>
    <content><![CDATA[<h2 id="1-Global-Vectors-for-Word-Representation-GloVe"><a href="#1-Global-Vectors-for-Word-Representation-GloVe" class="headerlink" title="1. Global Vectors for Word Representation(GloVe)"></a>1. Global Vectors for Word Representation(GloVe)</h2><h3 id="1-1-What’s-GloVe"><a href="#1-1-What’s-GloVe" class="headerlink" title="1.1 What’s GloVe?"></a>1.1 What’s GloVe?</h3><p>GloVe is a word representation tool based on global word frequency (count-based &amp; overall statistics). It can express a word into a vector of real numbers. These vectors some semantic characteristics between words are captured, such as similarity (analogity), analogy (analogy), etc. We can calculate the semantic similarity between two words through operations on vectors, such as Euclidean distance or cosine similarity.</p>
<h3 id="1-2-How-dose-it-work"><a href="#1-2-How-dose-it-work" class="headerlink" title="1.2 How dose it work?"></a>1.2 How dose it work?</h3><h4 id="1-2-1-Construct-a-co-occurrence-matrix"><a href="#1-2-1-Construct-a-co-occurrence-matrix" class="headerlink" title="1.2.1 Construct a co-occurrence matrix"></a>1.2.1 Construct a co-occurrence matrix</h4><p>According to the corpus to build a <a href="http://www.fanyeong.com/2017/10/10/word2vec/" target="_blank" rel="noopener">co-occurrence matrix</a> X, <strong>Each element in the matrix (X_{i,j}) represents the number of times the word (i) and the context word (j) appear together in a context window of a certain size. </strong>Generally speaking, the minimum unit of this number is 1, but GloVe does not think so: it proposes a decay function based on the distance between two words in the context window (d): (decay = 1/d) is used to calculate the weight, that is to say, <strong>the farther away the two words, the smaller the weight of the total count</strong>.</p>
<h4 id="1-2-2-Construct-the-approximate-relationship-between-Word-Vector-and-Co-occurrence-Matrix"><a href="#1-2-2-Construct-the-approximate-relationship-between-Word-Vector-and-Co-occurrence-Matrix" class="headerlink" title="1.2.2 Construct the approximate relationship between Word Vector and Co-occurrence Matrix"></a>1.2.2 Construct the approximate relationship between Word Vector and Co-occurrence Matrix</h4><p>The author of the <a href="https://www.aclweb.org/anthology/D14-1162" target="_blank" rel="noopener">paper</a> proposes the following formula to approximate the relationship between the two:</p>
<script type="math/tex; mode=display">
w_{i}^{T}\tilde{w_{j}} + b_i + \tilde{b_j} = \log(X_{ij}) \tag{1}</script><p>Among them, $(w_{i}^{T})$ and $ ( \tilde{ w_{j} }) $ are the word vectors we finally need to solve; $ (b_i)$  and $ (\tilde{b_j} ) $ Are the bias terms of the two word vectors.<br>Of course, you must have a lot of questions about this formula, such as how did it come from, why should you use this formula, and why should you construct two word vectors $ (w_{i}^{T})$  and $ (\tilde {w_{j}})$ ? We will introduce them in detail below.  </p>
<h4 id="1-2-3-Construct-loss-function"><a href="#1-2-3-Construct-loss-function" class="headerlink" title="1.2.3 Construct loss function"></a>1.2.3 Construct loss function</h4><p>With formula (1), we can construct its loss function:</p>
<script type="math/tex; mode=display">
J = \sum_{i,j=1}^{V} f(X_{ij})(w_{i}^{T}\tilde{w_{j}} + b_i + \tilde{b_j} – \log (X_{ij}) )^2 \tag{2}</script><p>The basic form of this loss function is the simplest mean square loss, but on this basis, a weight function$  (f(X_{ij})) $ is added, then what role does this function play, why should this function be added What? We know that in a corpus, there must be a lot of words that they appear together frequently (frequent co-occurrences), then we hope:</p>
<ol>
<li>The weight of these words is greater than the words that rarely appear together (rare co-occurrences), so if this function is a non-decreasing function (non-decreasing);</li>
<li>But we also don’t want this weight to be overweighted, it should not increase after reaching a certain level;</li>
<li>If the two words do not appear together, that is, $ (X_{ij}=0)$ , then they should not participate in the calculation of the loss function, that is, $ (f(x)) $ must satisfy $ (f(0)=0)$<br>There are many functions that meet the above two conditions, and the author uses the following form of the piecewise function:<script type="math/tex; mode=display">
f(x)=\begin{equation}
\begin{cases}
(x/x_{max})^{\alpha} & \text{if} \ x <x_{max} \\
1 & \text{otherwise}
\end{cases}
\end{equation} \tag{3}</script>The function image is shown below:</li>
</ol>
<p><img src="/blog/2020/06/26/notes-of-cs224n-part2/zE6t1ig.jpg" alt></p>
<p>In all experiments in this paper, the value of $ (\alpha) $ is 0.75, and the value of $ (x_{max})$  is 100. The above is the implementation details of GloVe, so how does GloVe train?</p>
<h4 id="1-2-4-Train-GloVe-Model"><a href="#1-2-4-Train-GloVe-Model" class="headerlink" title="1.2.4 Train GloVe Model"></a>1.2.4 Train GloVe Model</h4><p>Although many people claim that GloVe is an unsupervised learning method (because it does not require manual labeling), it actually has a label. This label is the $ (\log(X_{ in formula (2) ij}))$ , and the vectors $ (w)$  and $ (\tilde{w})$  in formula 2 are the parameters that need to be continuously updated/learned, so in essence its training method is no different from the supervised learning training method Not the same, all based on gradient descent. Specifically, the experiment in this paper is done as follows: AdaGrad’s gradient descent algorithm is used to randomly sample all non-zero elements in the matrix $ (X)$ , and the learning curvature is set to 0.05. If the vector size is less than 300, iterate 50 times, and vectors of other sizes iterate 100 times until convergence. The final learning is that the two vectors are $ (w)$  and $ (\tilde{w})$ , because (X) is symmetric, so in principle $ (w)$  and $ (\tilde{w})$  is also symmetrical, the only difference between them is that the initial values are different, which leads to different final values. So these two are actually equivalent and can be used as the final result. But in order to improve the robustness, we will eventually choose the sum of the two $ (w + \tilde{w})$  as the final vector (different initialization of the two is equivalent to adding different random noise, so it can improve the robustness Sex). After training a corpus of 40 billion tokens, the experimental results obtained are shown below:</p>
<p><img src="/blog/2020/06/26/notes-of-cs224n-part2/X6eVUJJ.jpg" alt></p>
<p>There are three indicators used in this graph: semantic accuracy, grammatical accuracy, and overall accuracy. Then it is not difficult to find that Vector Dimension can achieve the best at 300, and the context Windows size is roughly between 6 and 10.</p>
<h2 id="2-Evaluation-of-Word-Vectors"><a href="#2-Evaluation-of-Word-Vectors" class="headerlink" title="2. Evaluation of Word Vectors"></a>2. Evaluation of Word Vectors</h2><p>In this section, we discuss how we can quantitatively evaluate the quality of word vectors produced by such techniques.</p>
<h3 id="2-1-Intrinsic-Evaluation"><a href="#2-1-Intrinsic-Evaluation" class="headerlink" title="2.1 Intrinsic Evaluation"></a>2.1 Intrinsic Evaluation</h3><p>Intrinsic evaluation of word vectors is the evaluation of a set of word vectors generated by an embedding technique (such as Word2Vec or GloVe) on specific intermediate subtasks (such as analogy completion). These subtasks are typically simple and fast to compute and thereby allow us to help understand the system used to generate the word vectors. An intrinsic evaluation should typically return to us a number that indicates the performance of those word vectors on the evaluation subtask.</p>
<p>Motivation: Let us consider an example where our final goal is to create a question answering system which uses word vectors as inputs. One approach of doing so would be to train a machine learning system that:</p>
<ol>
<li>Takes words as inputs </li>
<li>Converts them to word vectors </li>
<li>Uses word vectors as inputs for an elaborate machine learning system </li>
<li>Maps the output word vectors by this system back to natural language words </li>
<li>Produces words as answers</li>
</ol>
<p>Of course, in the process of making such a state-of-the-art question-answering system, we will need to create optimal word-vector representations since they are used in downstream subsystems (such as deep neural networks). To do this in practice, we will need to tune many hyperparameters in the Word2Vec subsystem (such as the dimension of the word vector representation). While the idealistic approach is to retrain the entire system after any parametric changes in the Word2Vec subsystem, this is impractical from an engineering standpoint because the machine learning system (in step 3) is typically a deep neural network with millions of parameters that takes very long to train. In such a situation, we would want to come up with a simple intrinsic evaluation technique which can provide a measure of “goodness” of the word to word vector subsystem. Obviously, a requirement is that the intrinsic evaluation has a positive correlation with the final task performance.</p>
<h3 id="2-2-Extrinsic-Evaluation"><a href="#2-2-Extrinsic-Evaluation" class="headerlink" title="2.2 Extrinsic Evaluation"></a>2.2 Extrinsic Evaluation</h3><p>Extrinsic evaluation of word vectors is the evaluation of a set of word vectors generated by an embedding technique on the real task at hand. These tasks are typically elaborate and slow to compute. Using our example from above, the system which allows for the evaluation of answers from questions is the extrinsic evaluation system. Typically, optimizing over an underperforming extrinsic evaluation system does not allow us to determine which specific subsystem is at fault and this motivates the need for intrinsic evaluation.</p>
<h3 id="2-3-Summary"><a href="#2-3-Summary" class="headerlink" title="2.3 Summary"></a>2.3 Summary</h3><h5 id="Intrinsic-Evaluation"><a href="#Intrinsic-Evaluation" class="headerlink" title="Intrinsic Evaluation:"></a>Intrinsic Evaluation:</h5><ul>
<li>Evaluate specific intermediate tasks</li>
<li>Faster calculation speed</li>
<li>Help understand the subsystem</li>
<li>Need to be positively correlated with actual tasks to determine usefulness</li>
</ul>
<h5 id="Extrinsic-Evaluation"><a href="#Extrinsic-Evaluation" class="headerlink" title="Extrinsic Evaluation"></a>Extrinsic Evaluation</h5><ul>
<li>an Evaluation of the real task</li>
<li>Computing performance may be slow</li>
<li>It is unclear whether the subsystem is the problem, or other subsystems, or internal interactions</li>
<li>If replacing the subsystem can improve performance, then the change may be good</li>
</ul>
<h2 id="3-Training-for-Extrinsic-Tasks"><a href="#3-Training-for-Extrinsic-Tasks" class="headerlink" title="3. Training for Extrinsic Tasks"></a>3. Training for Extrinsic Tasks</h2><p>We have so far focused on intrinsic tasks and emphasized their importance in developing a good word embedding technique. Of course, the end goal of most real-world problems is to use the resulting word vectors for some other extrinsic task. Here we discuss the general approach for handling extrinsic tasks.</p>
<h3 id="3-1-Problem-Formulation"><a href="#3-1-Problem-Formulation" class="headerlink" title="3.1 Problem Formulation"></a>3.1 Problem Formulation</h3><p>Most NLP extrinsic tasks can be formulated as classification tasks. For instance, given a sentence, we can classify the sentence to have positive, negative or neutral sentiment. Similarly, in named-entity recognition (NER), given a context and a central word, we want to classify the central word to be one of many classes.</p>
<p>In typical machine learning tasks, we usually hold input data and target labels fixed and train weights using optimization techniques (such as gradient descent, L-BFGS, Newton’s method, etc.). In NLP applications however, we introduce the idea of retraining the input word vectors when we train for extrinsic tasks. Let us discuss when and why we should consider doing this.</p>
<h3 id="3-2-Retraining-Word-Vectors"><a href="#3-2-Retraining-Word-Vectors" class="headerlink" title="3.2 Retraining Word Vectors"></a>3.2 Retraining Word Vectors</h3><h3 id="3-3-Softmax-Classification-and-Regularization"><a href="#3-3-Softmax-Classification-and-Regularization" class="headerlink" title="3.3 Softmax Classification and Regularization"></a>3.3 Softmax Classification and Regularization</h3><h3 id="3-4-Window-Classification"><a href="#3-4-Window-Classification" class="headerlink" title="3.4 Window Classification"></a>3.4 Window Classification</h3><h3 id="3-5-Non-linear-Classifiers"><a href="#3-5-Non-linear-Classifiers" class="headerlink" title="3.5 Non-linear Classifiers"></a>3.5 Non-linear Classifiers</h3><h3 id="4-References"><a href="#4-References" class="headerlink" title="4. References"></a>4. References</h3><h5 id="1-GloVe-Global-Vectors-for-Word-Representation"><a href="#1-GloVe-Global-Vectors-for-Word-Representation" class="headerlink" title="1. GloVe: Global Vectors for Word Representation"></a>1. <a href="https://www.aclweb.org/anthology/D14-1162" target="_blank" rel="noopener">GloVe: Global Vectors for Word Representation</a></h5><h5 id="2-GloVe详解"><a href="#2-GloVe详解" class="headerlink" title="2. GloVe详解"></a>2. <a href="http://www.fanyeong.com/2018/02/19/glove-in-detail/" target="_blank" rel="noopener">GloVe详解</a></h5><h5 id="3-cs224n-2019-notes02-wordvecs2"><a href="#3-cs224n-2019-notes02-wordvecs2" class="headerlink" title="3. cs224n-2019-notes02-wordvecs2"></a>3. <a href="https://github.com/datawhalechina/team-learning/tree/master/04%20%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/Lecture/Lecture2/official_notes/cs224n-2019-notes02-wordvecs2.pdf" target="_blank" rel="noopener">cs224n-2019-notes02-wordvecs2</a></h5>]]></content>
      <categories>
        <category>入门</category>
        <category>NLP</category>
      </categories>
      <tags>
        <tag>NLP</tag>
      </tags>
  </entry>
  <entry>
    <title>Note of CS224n —— subword</title>
    <url>//blog/2020/06/29/notes-of-CS224n-part3.html</url>
    <content><![CDATA[<h2 id="1-Introduction"><a href="#1-Introduction" class="headerlink" title="1. Introduction"></a>1. Introduction</h2><p>The Word2vec model and GloVe model mentioned in the previous posts are basically based on the word which means word as the basic unit. But theirs disadvantage is that they cannot solve the out-of-vocabulary(OOV for short) that the word is not in the vocabulary. And they have a bad performance on processing the morphology.</p>
<p>Let’s take a look at these:</p>
<h3 id="1-1-Word-Level-Model"><a href="#1-1-Word-Level-Model" class="headerlink" title="1.1 Word-Level Model"></a>1.1 Word-Level Model</h3><p>Based on the basic unit — word, this method can well represent each word as a  vector in the vocabulary. Its disadvantages are as follow:</p>
<h4 id="1-1-1-OOV"><a href="#1-1-1-OOV" class="headerlink" title="1.1.1 OOV"></a>1.1.1 OOV</h4><ul>
<li>Problem: It’s easy to appear that the word we want doesn’t in the vocabulary;</li>
<li>Solution: Add more words into vocabulary</li>
</ul>
<h4 id="1-1-2-Improper-spelling"><a href="#1-1-2-Improper-spelling" class="headerlink" title="1.1.2 Improper spelling"></a>1.1.2 Improper spelling</h4><ul>
<li>Problem: The system is difficult to deal with the word which has unofficial spelling.</li>
<li>Solution: Correct the wrong spelling word or add rule constraints.</li>
</ul>
<h4 id="1-1-3-Name-Translation"><a href="#1-1-3-Name-Translation" class="headerlink" title="1.1.3 Name Translation"></a>1.1.3 Name Translation</h4><ul>
<li>Problem: It’s difficult to transliterate names.</li>
<li>Solution: Add rule constrains.</li>
</ul>
<h3 id="1-2-Character-Level-Model"><a href="#1-2-Character-Level-Model" class="headerlink" title="1.2 Character-Level Model"></a>1.2 Character-Level Model</h3><p>Based on character as the basic unit, this method can well vectorize each Char in the font. It’s good at solving OOV problems and having similar embedding among the words that have similar spelling.</p>
<h4 id="Problem"><a href="#Problem" class="headerlink" title="Problem:"></a>Problem:</h4><p>Compared to word-level, character-level input sentences become longer, making the data sparse, and the dependence on long distance is difficult to learn, and the training speed is reduced.</p>
<h4 id="Solution"><a href="#Solution" class="headerlink" title="Solution:"></a>Solution:</h4><p><a href="https://arxiv.org/abs/1610.03017" target="_blank" rel="noopener">Fully Character-Level Neural Machine Translation without Explicit Segmentation</a> introduced a way which uses multiple layers of convolution, pooling and highway layer to solve this problem. The structure of the encoder is shown below:</p>
<p><img src="/blog/2020/06/29/notes-of-CS224n-part3/encoder.jpg" alt></p>
<p>And how it works:</p>
<ol>
<li>The input characters first need to go through the Character embedding layer and be converted into character embeddings representation;</li>
<li>Convolution kernels with different window sizes are used to perform the convolution operation on the character embeddings of the input characters. The sizes of the windows used in the paper are 3, 4 and 5, respectively, that is, to learn Character-level 3-gram, 4-gram, 5-gram;</li>
<li>Perform max-pooling operations on the convolution results of different convolutional layers, that is, capture its most significant features to generate segment embedding;</li>
<li>The segment embedding passes through the Highway Network (some similar to the Residual network, which facilitates the flow of information in the deep network, but some gates are added to control the flow of information);</li>
<li>The output results go through the single layer BiGRU to get the final encoder output;</li>
<li>The decoder uses the Attention mechanism and character level GRU to decode it.</li>
</ol>
<p>The experimental results show that the character-based model can better handle the OOV problem, and for multi-language scenarios, it can better learn the common morphemes among languages. And it can capture the 3-gram, 4-gram, 5-gram information of the sentence, which is also the prototype of the idea of FastText later.</p>
<h3 id="1-3-Subword-Model"><a href="#1-3-Subword-Model" class="headerlink" title="1.3 Subword Model"></a>1.3 Subword Model</h3><p>Subword model is a model created by taking a component between characters and words as the basic unit. It is divided into Byte Pair Encoding (BPE) and SentencePiece. </p>
<h2 id="2-Sub-word-Model"><a href="#2-Sub-word-Model" class="headerlink" title="2. Sub-word Model"></a>2. Sub-word Model</h2><p>Sub-word model has now become an important NLP model performance improvement method. Since BERT was born in 2018 and swept through the major rankings in the NLP world, various pre-trained language models have emerged like mushrooms, among which the Sub-word model has become a standard. And it has great advantages compared with the traditional space separation tokenization technology.</p>
<h3 id="2-1-Byte-Pair-Enconding-BPE"><a href="#2-1-Byte-Pair-Enconding-BPE" class="headerlink" title="2.1 Byte Pair Enconding(BPE)"></a>2.1 Byte Pair Enconding(BPE)</h3><p>BPE is one of the compression algorithms. The main idea is to replace the frequently occurring byte pair with a new byte. For example, if (‘A’,’B’) appears frequently in sequence, then use a new flag (‘AB’) To replace them. </p>
<p>Given a text library, our initial vocabulary contains only all single characters, and then continuously add the n-gram pair with the highest frequency as a new n-gram to the vocabulary until the size of the vocabulary reaches a certain goal we set.</p>
<p>Google’s NMT model also evolved from BPE, one called word-piece model and one called sentence-piece model. The word-piece model does not select the n-gram with the highest frequency each time, but selects the n-gram that can reduce the complexity of the language model each time. </p>
<h3 id="2-2-Sentence-Piece"><a href="#2-2-Sentence-Piece" class="headerlink" title="2.2 Sentence-Piece"></a>2.2 Sentence-Piece</h3><p>The sentence-piece model regards the gap between words as a word, so that the entire sentence can be directly processed without preprocessing into words and then embedding.</p>
<h2 id="3-Hybrid-character-and-word-level-models"><a href="#3-Hybrid-character-and-word-level-models" class="headerlink" title="3. Hybrid character and word-level models"></a>3. Hybrid character and word-level models</h2><p>The key idea: most of the time, the word-level model is used for translation. Only when the words of rare or unseen are encountered, the character-level model will be used to assist. This approach has produced very good results.</p>
<h2 id="4-References"><a href="#4-References" class="headerlink" title="4. References"></a>4. References</h2><h5 id="1-Achieving-Open-Vocabulary-Neural-Machine-Translation-with-Hybrid-Word-Character-Models"><a href="#1-Achieving-Open-Vocabulary-Neural-Machine-Translation-with-Hybrid-Word-Character-Models" class="headerlink" title="1. Achieving Open Vocabulary Neural Machine Translation with Hybrid Word-Character Models"></a>1. <a href="https://arxiv.org/abs/1604.00788v1" target="_blank" rel="noopener">Achieving Open Vocabulary Neural Machine Translation with Hybrid Word-Character Models</a></h5><h5 id="2-Fully-Character-Level-Neural-Machine-Translation-without-Explicit-Segmentation"><a href="#2-Fully-Character-Level-Neural-Machine-Translation-without-Explicit-Segmentation" class="headerlink" title="2.Fully Character-Level Neural Machine Translation without Explicit Segmentation"></a>2.<a href="https://arxiv.org/abs/1610.03017" target="_blank" rel="noopener">Fully Character-Level Neural Machine Translation without Explicit Segmentation</a></h5><h5 id="3-Enriching-Word-Vectors-with-Subword-Information"><a href="#3-Enriching-Word-Vectors-with-Subword-Information" class="headerlink" title="3. Enriching Word Vectors with Subword Information"></a>3. <a href="https://arxiv.org/pdf/1607.04606.pdf" target="_blank" rel="noopener">Enriching Word Vectors with Subword Information</a></h5>]]></content>
      <categories>
        <category>入门</category>
        <category>NLP</category>
      </categories>
      <tags>
        <tag>NLP</tag>
      </tags>
  </entry>
  <entry>
    <title>Note of CS224n —— ELMO &amp; GPT &amp; Bert</title>
    <url>//blog/2020/07/03/notes-of-CS224n-part4.html</url>
    <content><![CDATA[<h2 id="1-ELMo"><a href="#1-ELMo" class="headerlink" title="1. ELMo"></a>1. ELMo</h2><p>In the previous work of word2vec and GloVe, each word corresponds to a vector, which is powerless for polysemous words. And as the language environment changes, these vectors cannot accurately express the corresponding features. The authors of ELMo believe that a good word representation model should take into account two issues at the same time: one is the complex semantic and grammatical characteristics of word usage; and the other is that these usages should change with the change of language environment.</p>
<p><strong>The characteristics of ELMo</strong> : the representation of each word is a function of the entire input sentence. </p>
<h3 id="1-1-How-ELMo-works"><a href="#1-1-How-ELMo-works" class="headerlink" title="1.1 How ELMo works"></a>1.1 How ELMo works</h3><ol>
<li>Pre-train biLM models on large corpora. The model is composed of two layers of bi-LSTM, and the models are connected by residual connection. Moreover, the author believes that the low-level bi-LSTM layer can extract the syntactic information in the corpus, and the high-level bi-LSTM can extract the semantic information in the corpus.</li>
<li>In our training corpus (removing labels), fine-tuning the pre-trained biLM model. This step can be seen as the domain transfer of biLM.</li>
<li>The word embedding generated by ELMo is used as the input of the task, and sometimes it can be added both during input and output.</li>
</ol>
<p>ELMo got its name (Embeddings from Language Models). In order to be used in downstream NLP tasks, generally use the corpus of downstream tasks (note that the label is omitted here) to fine-tune the language model. This fine-tuning is equivalent to a domain transfer; then use the label information for supervised learning.</p>
<p><img src="/blog/2020/07/03/notes-of-CS224n-part4/useELMo.png" alt></p>
<h3 id="1-2-Bidirectional-language-models"><a href="#1-2-Bidirectional-language-models" class="headerlink" title="1.2 Bidirectional language models"></a>1.2 Bidirectional language models</h3><p>ELMo, as the name implies, is embeddings from Language Models, to be precise from Bidirectional language models. It can be expressed as:</p>
<p><img src="https://pirctures.oss-cn-beijing.aliyuncs.com/img/1.png" alt></p>
<p><strong>Forward LSTM structure:</strong></p>
<p><img src="/blog/2020/07/03/notes-of-CS224n-part4/f1.png" alt></p>
<p><strong>Reverse LSTM structure:</strong></p>
<p><img src="/blog/2020/07/03/notes-of-CS224n-part4/f2.png" alt></p>
<p><strong>Maximum likelihood function:</strong></p>
<p><img src="/blog/2020/07/03/notes-of-CS224n-part4/f3.png" alt></p>
<h3 id="1-3-summary"><a href="#1-3-summary" class="headerlink" title="1.3 summary"></a>1.3 summary</h3><p><img src="/blog/2020/07/03/notes-of-CS224n-part4/great.png" alt></p>
<p>In general, ELMo provides dynamic representation at the word level, which can effectively capture contextual information and solve the problem of polysemy.</p>
<h2 id="2-GPT"><a href="#2-GPT" class="headerlink" title="2. GPT"></a>2. GPT</h2><h3 id="2-1-Introduce"><a href="#2-1-Introduce" class="headerlink" title="2.1 Introduce"></a>2.1 Introduce</h3><p>OpenAI proposed the GPT model in the paper “Improving Language Understanding by Generative Pre-Training”, and later proposed the GPT2 model in the paper “Language Models are Unsupervised Multitask Learners”. The model structure of GPT2 and GPT is not much different, but a larger data set is used for the experiment.</p>
<p>The training method adopted by GPT is divided into two steps. The first step is to train the language model using an unlabeled text data set. The second step is to fine-tune the model according to specific downstream tasks, such as QA, text classification, etc.</p>
<h3 id="2-2-Structure"><a href="#2-2-Structure" class="headerlink" title="2.2 Structure"></a>2.2 Structure</h3><p>GPT uses Transformer’s Decoder structure and makes some changes to Transformer Decoder. The original Decoder contains two Multi-Head Attention structures, and GPT only retains Mask Multi-Head Attention.</p>
<p><img src="/blog/2020/07/03/notes-of-CS224n-part4/p1.png" alt="GPT&#39;s Decoder"></p>
<p>The following figure is the overall model of GPT, which contains 12 Decoders:</p>
<p><img src="/blog/2020/07/03/notes-of-CS224n-part4/p2.png" alt></p>
<h3 id="2-3-Summary"><a href="#2-3-Summary" class="headerlink" title="2.3 Summary"></a>2.3 Summary</h3><p>The GPT pre-training uses the above to predict the next word. GPT is more suitable for the task of text generation, because text generation is usually based on the information currently available to generate the next word.</p>
<h2 id="3-BERT"><a href="#3-BERT" class="headerlink" title="3. BERT"></a>3. BERT</h2><h3 id="3-1-Introduce"><a href="#3-1-Introduce" class="headerlink" title="3.1 Introduce"></a>3.1 Introduce</h3><p>BERT(Bidirectional Encoder Representation from Transformers) is the encoder of the bidirectional Transformer. The model architecture of BERT is based on multi-layer bidirectional conversion decoding. Because the decoder cannot obtain the information to be predicted, the main innovation of the model is in the pre-traing method, Which uses Masked LM and Next Sentence Prediction to capture word and sentence level representation respectively.</p>
<p>“Bidirectional” means that when the model is processing a certain word, it can use both the previous word and the following words. BERT is different from the traditional language model. It is not giving you all the previous words so that you can predict the most probable current word, but covering some words at random, and then use all the words that are not covered to make predictions.</p>
<h3 id="3-2-Structure"><a href="#3-2-Structure" class="headerlink" title="3.2 Structure"></a>3.2 Structure</h3><p><img src="/blog/2020/07/03/notes-of-CS224n-part4/BERT.png" alt></p>
<p>BERT provides a simple and a complex model, the corresponding hyperparameters are as follows:</p>
<p><strong>BERT-base</strong>: L=12, H=768, A=12, total parameter 110M;<br><strong>BERT-large</strong>: L=24, H=1024, A=16, the total amount of parameters is 340M;<br>In the above hyperparameters, L represents the number of layers of the network (the number of Transformer blocks), A represents the number of self-Attention in Multi-Head Attention, and the filter size is 4H.</p>
<h3 id="3-3-Pre-train-task"><a href="#3-3-Pre-train-task" class="headerlink" title="3.3 Pre-train task"></a>3.3 Pre-train task</h3><p>BERT is a multi-task model. Its task is composed of two self-supervised tasks, namely MLM and NSP.</p>
<h4 id="3-3-1-Task-1：-Masked-Language-Model"><a href="#3-3-1-Task-1：-Masked-Language-Model" class="headerlink" title="3.3.1 Task #1： Masked Language Model"></a>3.3.1 Task #1： Masked Language Model</h4><p>Masked Language Model (MLM) core idea is taken from a paper published by Wilson Taylor in 1953. It refers to masking some words from the input expectations during training, and then predicting the words through the context. This task is very similar to the cloze that we often do in middle school. Just like traditional language model algorithms and RNN matching, this property of MLM matches the structure of Transformer very well.</p>
<h4 id="3-3-2-Task-2-Next-Sentence-Prediction"><a href="#3-3-2-Task-2-Next-Sentence-Prediction" class="headerlink" title="3.3.2 Task #2: Next Sentence Prediction"></a>3.3.2 Task #2: Next Sentence Prediction</h4><p>The task of Next Sentence Prediction (NSP) is to determine whether sentence B is the following of sentence A. If yes, output <strong>“IsNext”</strong>, otherwise output <strong>“NotNext”</strong>. The training data is generated by randomly extracting two consecutive sentences from the parallel corpus, of which 50% retain the two extracted sentences, which are in accordance with the <strong>IsNext</strong> relationship, and the other 50% of the second sentence is randomly extracted from the expected, they The relationship is <strong>NotNext</strong>. </p>
<h2 id="4-References"><a href="#4-References" class="headerlink" title="4. References"></a>4. References</h2><h5 id="1-Deep-contextualized-word-representations"><a href="#1-Deep-contextualized-word-representations" class="headerlink" title="1. Deep contextualized word representations"></a>1. <a href="https://arxiv.org/pdf/1802.05365.pdf" target="_blank" rel="noopener">Deep contextualized word representations</a></h5><h5 id="2-Improving-Language-Understanding-by-Generative-Pre-Training"><a href="#2-Improving-Language-Understanding-by-Generative-Pre-Training" class="headerlink" title="2. Improving Language Understanding by Generative Pre-Training"></a>2. <a href="https://s3-us-west-2.amazonaws.com/openai-assets/research-covers/language-unsupervised/language_understanding_paper.pdf" target="_blank" rel="noopener">Improving Language Understanding by Generative Pre-Training</a></h5><h5 id="3-OpenAI-GPT-和-GPT2-模型详解"><a href="#3-OpenAI-GPT-和-GPT2-模型详解" class="headerlink" title="3. OpenAI GPT 和 GPT2 模型详解"></a>3. <a href="https://baijiahao.baidu.com/s?id=1652093322137148754" target="_blank" rel="noopener">OpenAI GPT 和 GPT2 模型详解</a></h5><h5 id="4-BERT-Pre-training-of-Deep-Bidirectional-Transformers-for-Language-Understanding"><a href="#4-BERT-Pre-training-of-Deep-Bidirectional-Transformers-for-Language-Understanding" class="headerlink" title="4. BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"></a>4. <a href="https://arxiv.org/pdf/1810.04805.pdf" target="_blank" rel="noopener">BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding</a></h5><h5 id="5-BERT详解"><a href="#5-BERT详解" class="headerlink" title="5. BERT详解"></a>5. <a href="https://zhuanlan.zhihu.com/p/48612853" target="_blank" rel="noopener">BERT详解</a></h5>]]></content>
      <categories>
        <category>入门</category>
        <category>NLP</category>
      </categories>
      <tags>
        <tag>NLP</tag>
      </tags>
  </entry>
  <entry>
    <title>Note of CS224n —— Homework</title>
    <url>//blog/2020/07/06/notes-of-CS224n-part5.html</url>
    <content><![CDATA[<h2 id="preview-work"><a href="#preview-work" class="headerlink" title="preview work"></a>preview work</h2><p><a href="http://7497.xyz/blog/2020/06/26/exploring-of-word2vec.html" target="_blank" rel="noopener">Exploring of Word2vec</a></p>
<h2 id="Homework-reference"><a href="#Homework-reference" class="headerlink" title="Homework reference"></a>Homework reference</h2><p><a href="https://github.com/exuding/NLP/blob/master/bert_classification.ipynb" target="_blank" rel="noopener">fastText_classification.ipynb from winter</a></p>
<h2 id="Next"><a href="#Next" class="headerlink" title="Next"></a>Next</h2><p>we are planning to attend a NLP contest to learn more about it!!</p>
]]></content>
      <categories>
        <category>入门</category>
        <category>NLP</category>
      </categories>
      <tags>
        <tag>NLP</tag>
      </tags>
  </entry>
  <entry>
    <title>News Text Classification —— Tianchi Competition Understanding</title>
    <url>//blog/2020/07/21/news-text-classification-notes1.html</url>
    <content><![CDATA[<h2 id="1-Intros"><a href="#1-Intros" class="headerlink" title="1. Intros"></a>1. Intros</h2><p>I joined in a NLP team learning activity held by an open-source organization <a href="https://datawhale.club/" target="_blank" rel="noopener">Datawhale</a> again. This time, we’re gonna explore News Text Classification Challenge.</p>
<p>This is a classic text classification problem which requires players to classify news categories based on news text characters. And this challenge is held by Datawhale and Tianchi, and with the help of Datawhale, we can learn more about the knowledge points of NLP preprocessing, model construction and model training.</p>
<p>Here’s the competition: <a href="https://tianchi.aliyun.com/competition/entrance/531810/introduction" target="_blank" rel="noopener">https://tianchi.aliyun.com/competition/entrance/531810/introduction</a></p>
<h2 id="2-Understanding"><a href="#2-Understanding" class="headerlink" title="2. Understanding"></a>2. Understanding</h2><h3 id="2-1-Data"><a href="#2-1-Data" class="headerlink" title="2.1 Data"></a>2.1 Data</h3><p>The contest question use anonymously processed news data as contest question data, and the dataset is visible and downloadable after registration. The contest question data is news text and is anonymized according to character level. Integrate and divide 14 candidate classification categories: finance, lottery, real estate, stocks, home furnishing, education, technology, society, fashion, current affairs, sports, constellation, games and entertainment text data.</p>
<p>The question data consists of the following parts: 20w samples in the training set, about 5w samples in the test set A, and about 5w samples in the test set B. </p>
<p>The source of the question data is news on the Internet, which is collected and processed anonymously. Therefore, the contestants can perform data analysis on their own, and can give full play to their strengths to complete various feature projects, without restricting the use of any external data and models.</p>
<h3 id="2-2-Label"><a href="#2-2-Label" class="headerlink" title="2.2 Label"></a>2.2 Label</h3><p>The corresponding relationship of the labels in the data set is as follows: </p>
<blockquote>
<p>{‘Technology’: 0,’Stocks’: 1,’Sports’: 2,’Entertainment’: 3,’Current Affairs’: 4,’Society’: 5,’Education’ : 6,’Finance’: 7,’Home Furnishing’: 8,’Game’: 9,’Property’: 10,’Fashion’: 11,’Lottery’: 12,’Constellation’: 13}</p>
</blockquote>
<p>training set columns:</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>label</th>
<th>text</th>
</tr>
</thead>
<tbody>
<tr>
<td>2</td>
<td>2967 6758 339 2021 1854 3731 4109 3792 4149 1519 2058 3912 2465 2410 1219 6654 7539 264 2456 4811 12…</td>
</tr>
</tbody>
</table>
</div>
<h3 id="2-3-Evaluation"><a href="#2-3-Evaluation" class="headerlink" title="2.3 Evaluation"></a>2.3 Evaluation</h3><p>The evaluation standard is the average value of the category <code>f1_score</code>. The results submitted by the players are compared with the categories of the actual test set. The larger the result, the better.</p>
<p>formula:</p>
<script type="math/tex; mode=display">
F1 = \frac{1}{\frac{1}{2} * (\frac{1}{precision} + \frac{1}{recall})}= 2 * \frac{(precision * recall)}{(precison + recall)}</script><p>Mathematically, F1-Socre is defined as the harmonic mean of precision and recall. From the formula, we can see that the size of F1 is affected by Precision and Recall, that is, the short board effect, so F1 Score is more balanced than the direct average result, and it can better explain the quality of a model.</p>
<p>coding example:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> f1_score</span><br><span class="line">y_true = [<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>]</span><br><span class="line">y_pred = [<span class="number">0</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>]</span><br><span class="line">f1_score(y_true, y_pred, average=<span class="string">'macro'</span>)</span><br></pre></td></tr></table></figure>
<p>output: 0.26666666666666666</p>
<h3 id="2-4-Solving-Ideas"><a href="#2-4-Solving-Ideas" class="headerlink" title="2.4 Solving Ideas"></a>2.4 Solving Ideas</h3><p><strong>Analysis</strong>: The essence of this challenge is a text classification problem, which needs to be classified according to the characters of each sentence. However, the data given in the question is anonymized, and operations such as Chinese word segmentation cannot be used directly. This is the difficulty of this challenge.</p>
<p>Therefore, the difficulty of this competition is the need to model anonymous characters to complete the process of text classification. Since text data is a typical unstructured data, it may involve two parts: <code>feature extraction</code> and <code>classification model</code>. In order to reduce the difficulty of the competition, Datawhale has provided some ideas for solving problems for your reference:</p>
<h5 id="Idea-1-TF-IDF-machine-learning-classifier"><a href="#Idea-1-TF-IDF-machine-learning-classifier" class="headerlink" title="Idea 1: TF-IDF + machine learning classifier"></a>Idea 1: TF-IDF + machine learning classifier</h5><p>Use TF-IDF to extract features directly from the text, and use the classifier to classify. In the choice of classifier, SVM, LR, or XGBoost can be used.</p>
<h5 id="Idea-2-FastText"><a href="#Idea-2-FastText" class="headerlink" title="Idea 2: FastText"></a>Idea 2: FastText</h5><p>FastText is an entry-level word vector. Using the FastText tool provided by Facebook, you can quickly build a classifier.</p>
<h5 id="Idea-3-WordVec-Deep-Learning-Classifier"><a href="#Idea-3-WordVec-Deep-Learning-Classifier" class="headerlink" title="Idea 3: WordVec + Deep Learning Classifier"></a>Idea 3: WordVec + Deep Learning Classifier</h5><p>WordVec is an advanced word vector, and the classification is completed by constructing a deep learning classification. The network structure of deep learning classification can choose TextCNN, TextRNN or BiLSTM.</p>
<h5 id="Idea-4-Bert-word-vector"><a href="#Idea-4-Bert-word-vector" class="headerlink" title="Idea 4: Bert word vector"></a>Idea 4: Bert word vector</h5><p>Bert is a highly matched word vector with powerful modeling and learning capabilities.</p>
<h2 id="3-What’s-Next"><a href="#3-What’s-Next" class="headerlink" title="3. What’s Next?"></a>3. What’s Next?</h2><p>Read the data in and try idea 1.</p>
<h2 id="4-References"><a href="#4-References" class="headerlink" title="4. References"></a>4. References</h2><h5 id="1-Task1-赛题理解"><a href="#1-Task1-赛题理解" class="headerlink" title="1. Task1 赛题理解"></a>1. <a href="https://tianchi.aliyun.com/notebook-ai/detail?spm=5176.12586969.1002.6.6406111aIKCSLV&amp;postId=118252" target="_blank" rel="noopener">Task1 赛题理解</a></h5><h5 id="2-通过实例来梳理概念-：准确率-Accuracy-、精准率-Precision-、召回率-Recall-和-F值"><a href="#2-通过实例来梳理概念-：准确率-Accuracy-、精准率-Precision-、召回率-Recall-和-F值" class="headerlink" title="2. 通过实例来梳理概念 ：准确率 (Accuracy)、精准率(Precision)、召回率(Recall)和 F值"></a>2. <a href="https://mp.weixin.qq.com/s/d5d3b3tnetqYKuckfUI08w" target="_blank" rel="noopener">通过实例来梳理概念 ：准确率 (Accuracy)、精准率(Precision)、召回率(Recall)和 F值</a></h5>]]></content>
      <categories>
        <category>入门</category>
        <category>NLP</category>
        <category>classification</category>
      </categories>
      <tags>
        <tag>NLP</tag>
      </tags>
  </entry>
  <entry>
    <title>News Text Classification —— Data Analysis</title>
    <url>//blog/2020/07/22/news-text-classification-notes2.html</url>
    <content><![CDATA[<h2 id="1-Read-Dataset"><a href="#1-Read-Dataset" class="headerlink" title="1. Read Dataset"></a>1. Read Dataset</h2><p>The dataset is stored in csv format, we can use pandas to read it. The <code>read_csv</code>  function in pandas has three parameter assignments here:</p>
<ul>
<li>The read file path,  you can use a relative path or an absolute path;</li>
<li>Separator sep, which is the character to be divided in each column, just set to ‘<code>\t</code>;</li>
<li>The number of rows read, <code>nrows</code>, is the number of rows of the file read this time, which is a numeric type;</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line">train_df = pd.read_csv(<span class="string">'/kaggle/input/newsclassestestdata/train_set.csv/train_set.csv'</span>, sep=<span class="string">'\t'</span>)</span><br><span class="line">train_df.head()</span><br></pre></td></tr></table></figure>
<p>output:</p>
<p><img src="/blog/2020/07/22/news-text-classification-notes2/p.png" alt></p>
<h2 id="2-Analysis"><a href="#2-Analysis" class="headerlink" title="2. Analysis"></a>2. Analysis</h2><h3 id="2-1-Sentence-length-analysis"><a href="#2-1-Sentence-length-analysis" class="headerlink" title="2.1 Sentence length analysis"></a>2.1 Sentence length analysis</h3><p>In this question, the characters of each line of sentences are separated by spaces, so you can directly count the number of words to get the length of each sentence. The statistics are as follows:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">%pylab inline</span><br><span class="line">train_df[<span class="string">'text_len'</span>] = train_df[<span class="string">'text'</span>].apply(<span class="keyword">lambda</span> x: len(x.split(<span class="string">' '</span>)))</span><br><span class="line">print(train_df[<span class="string">'text_len'</span>].describe())</span><br></pre></td></tr></table></figure>
<p>output:</p>
<p><img src="/blog/2020/07/22/news-text-classification-notes2/p1.png" alt></p>
<p>The statistics of news sentences can be concluded that the text given in this contest is relatively long, each sentence is composed of about 907 characters on average, the shortest sentence length is 2, and the longest sentence length is 57921.</p>
<p>The following figure draws a histogram of sentence length:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">_ = plt.hist(train_df[<span class="string">'text_len'</span>], bins=<span class="number">200</span>)</span><br><span class="line">plt.xlabel(<span class="string">'Text char count'</span>)</span><br><span class="line">plt.title(<span class="string">"Histogram of char count"</span>)</span><br></pre></td></tr></table></figure>
<p><img src="/blog/2020/07/22/news-text-classification-notes2/p2.png" alt></p>
<p>It can be seen that the length of most sentences is within 2000.</p>
<h3 id="2-2-News-category-distribution"><a href="#2-2-News-category-distribution" class="headerlink" title="2.2 News category distribution"></a>2.2 News category distribution</h3><p>Next, you can perform distribution statistics on the categories of the data set, and specifically count the number of samples of each type of news.</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">train_df[<span class="string">'label'</span>].value_counts().plot(kind=<span class="string">'bar'</span>)</span><br><span class="line">plt.title(<span class="string">'News class count'</span>)</span><br><span class="line">plt.xlabel(<span class="string">"category"</span>)</span><br></pre></td></tr></table></figure>
<p>output:</p>
<p><img src="/blog/2020/07/22/news-text-classification-notes2/p3.png" alt></p>
<p>The corresponding relationship of the labels in the data set is as follows: </p>
<blockquote>
<p>{‘Technology’: 0,’Stocks’: 1,’Sports’: 2,’Entertainment’: 3,’Current Affairs’: 4,’Society’: 5,’Education’ : 6,’Finance’: 7,’Home Furnishing’: 8,’Game’: 9,’Property’: 10,’Fashion’: 11,’Lottery’: 12,’Constellation’: 13}</p>
</blockquote>
<p>It can be seen from the statistical results that there is a relatively uneven distribution of the data set categories of the competition questions. In the training set, technology news is the most, followed by stock news, and the least news is constellation news.</p>
<h3 id="2-3-Character-distribution-statistics"><a href="#2-3-Character-distribution-statistics" class="headerlink" title="2.3 Character distribution statistics"></a>2.3 Character distribution statistics</h3><h5 id="2-3-1-Count-the-number-of-occurrences-of-each-character："><a href="#2-3-1-Count-the-number-of-occurrences-of-each-character：" class="headerlink" title="2.3.1 Count the number of occurrences of each character："></a>2.3.1 Count the number of occurrences of each character：</h5><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> Counter</span><br><span class="line">all_lines = <span class="string">' '</span>.join(list(train_df[<span class="string">'text'</span>]))</span><br><span class="line">word_count = Counter(all_lines.split(<span class="string">" "</span>))</span><br><span class="line">word_count = sorted(word_count.items(), key=<span class="keyword">lambda</span> d:d[<span class="number">1</span>], reverse = <span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">print(len(word_count))</span><br><span class="line">print(word_count[<span class="number">0</span>])</span><br><span class="line">print(word_count[<span class="number">-1</span>])</span><br></pre></td></tr></table></figure>
<p>output:</p>
<p><img src="/blog/2020/07/22/news-text-classification-notes2/p4.png" alt></p>
<h5 id="2-3-2-Count-the-number-of-times-different-characters-appear-in-sentences"><a href="#2-3-2-Count-the-number-of-times-different-characters-appear-in-sentences" class="headerlink" title="2.3.2 Count the number of times different characters appear in sentences:"></a>2.3.2 Count the number of times different characters appear in sentences:</h5><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">train_df[<span class="string">'text_unique'</span>] = train_df[<span class="string">'text'</span>].apply(<span class="keyword">lambda</span> x: <span class="string">' '</span>.join(list(set(x.split(<span class="string">' '</span>)))))</span><br><span class="line">all_lines = <span class="string">' '</span>.join(list(train_df[<span class="string">'text_unique'</span>]))</span><br><span class="line">word_count = Counter(all_lines.split(<span class="string">" "</span>))</span><br><span class="line">word_count = sorted(word_count.items(), key=<span class="keyword">lambda</span> d:int(d[<span class="number">1</span>]), reverse = <span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">print(word_count[<span class="number">0</span>])</span><br><span class="line">print(word_count[<span class="number">1</span>])</span><br><span class="line">print(word_count[<span class="number">2</span>])</span><br></pre></td></tr></table></figure>
<p>output:</p>
<p><img src="/blog/2020/07/22/news-text-classification-notes2/p5.png" alt></p>
<p>We can see that the coverage of characters 3750, characters 900 and characters 648 in 20w news is close to 99%, most likely they are punctuation marks.</p>
<h5 id="2-3-3-Assuming-that-character-3750-character-900-and-character-648-are-sentence-punctuation-marks-let’s-take-a-look-at-how-many-sentences-each-news-article-has-on-average"><a href="#2-3-3-Assuming-that-character-3750-character-900-and-character-648-are-sentence-punctuation-marks-let’s-take-a-look-at-how-many-sentences-each-news-article-has-on-average" class="headerlink" title="2.3.3 Assuming that character 3750, character 900 and character 648 are sentence punctuation marks, let’s take a look at how many sentences each news article has on average:"></a>2.3.3 Assuming that character 3750, character 900 and character 648 are sentence punctuation marks, let’s take a look at how many sentences each news article has on average:</h5><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">train_df[<span class="string">'sentence_count1'</span>] = train_df[<span class="string">'text'</span>].apply(<span class="keyword">lambda</span> x: len(x.split(<span class="string">'3750'</span>)))</span><br><span class="line">train_df[<span class="string">'sentence_count2'</span>] = train_df[<span class="string">'text'</span>].apply(<span class="keyword">lambda</span> x: len(x.split(<span class="string">'900'</span>)))</span><br><span class="line">train_df[<span class="string">'sentence_count3'</span>] = train_df[<span class="string">'text'</span>].apply(<span class="keyword">lambda</span> x: len(x.split(<span class="string">'648'</span>)))</span><br><span class="line">train_df[<span class="string">'sentence_count'</span>] = train_df[<span class="string">'text'</span>].apply(<span class="keyword">lambda</span> x: len(x.split(<span class="string">'3750|900|648'</span>)))</span><br><span class="line">print(train_df[<span class="string">'sentence_count1'</span>].describe())</span><br><span class="line">print(train_df[<span class="string">'sentence_count2'</span>].describe())</span><br><span class="line">print(train_df[<span class="string">'sentence_count3'</span>].describe())</span><br><span class="line">print(train_df[<span class="string">'sentence_count'</span>].describe())</span><br></pre></td></tr></table></figure>
<p>output:</p>
<p><img src="/blog/2020/07/22/news-text-classification-notes2/p6.png" alt></p>
<p>We can see that the average length of the sentence is about 30 characters.</p>
<h5 id="2-3-4-Count-the-most-frequent-characters-in-each-type-of-news"><a href="#2-3-4-Count-the-most-frequent-characters-in-each-type-of-news" class="headerlink" title="2.3.4 Count the most frequent characters in each type of news:"></a>2.3.4 Count the most frequent characters in each type of news:</h5><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">14</span>):</span><br><span class="line">    all_lines = <span class="string">' '</span>.join(train_df[train_df[<span class="string">'label'</span>]==i][<span class="string">'text'</span>])</span><br><span class="line">    word_count = Counter(all_lines.split(<span class="string">" "</span>))</span><br><span class="line">    word_count = sorted(word_count.items(), key=<span class="keyword">lambda</span> d: int(d[<span class="number">1</span>]), reverse = <span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">    print(i,word_count[<span class="number">0</span>])</span><br></pre></td></tr></table></figure>
<p>output:</p>
<p><img src="/blog/2020/07/22/news-text-classification-notes2/p7.png" alt></p>
<p>now we can tell the character <code>3750</code> is probably a punctuation mark!</p>
<h2 id="3-summary"><a href="#3-summary" class="headerlink" title="3. summary"></a>3. summary</h2><p>Through the above analysis, we can draw the following conclusions:</p>
<ul>
<li>The 1,000 sentences selected in the contest question contain an average of 904 characters per news, and some news characters are longer;</li>
<li>The distribution of news categories in the contest questions is uneven, the sample size of stock news is close to more than 200, and the sample size of lottery news is less than 10;</li>
<li>A total of nearly 4000 characters are included in the 1000 sentences of news;<br>‘3750’, ‘900’, and ‘648’ appear the most often, and it is inferred that they may be punctuation marks.</li>
<li>The average number of characters in each news item is large and may need to be truncated;</li>
<li>Due to the imbalance of the categories, it will seriously affect the accuracy of the model;</li>
<li>For further optimization, hope to infer stop words and remove noise;</li>
<li>Try to see if adding a clean data set can enhance the effect.</li>
</ul>
]]></content>
      <categories>
        <category>入门</category>
        <category>NLP</category>
        <category>classification</category>
      </categories>
      <tags>
        <tag>NLP</tag>
      </tags>
  </entry>
  <entry>
    <title>News Text Classification with ML</title>
    <url>//blog/2020/07/24/news-text-classification-notes3.html</url>
    <content><![CDATA[<h2 id="1-Count-Vectors-RidgeClassifier"><a href="#1-Count-Vectors-RidgeClassifier" class="headerlink" title="1. Count Vectors + RidgeClassifier"></a>1. Count Vectors + RidgeClassifier</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Count Vectors + RidgeClassifier</span></span><br><span class="line"><span class="keyword">from</span> sklearn.feature_extraction.text <span class="keyword">import</span> CountVectorizer</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> RidgeClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> f1_score</span><br><span class="line"></span><br><span class="line">train_df = pd.read_csv(<span class="string">'/kaggle/input/newsclassestestdata/train_set.csv/train_set.csv'</span>, sep=<span class="string">'\t'</span>, nrows=<span class="number">15000</span>)</span><br><span class="line"></span><br><span class="line">vectorizer = CountVectorizer(max_features=<span class="number">3000</span>)</span><br><span class="line">train_test = vectorizer.fit_transform(train_df[<span class="string">'text'</span>])</span><br><span class="line"></span><br><span class="line">clf = RidgeClassifier()</span><br><span class="line">clf.fit(train_test[:<span class="number">10000</span>], train_df[<span class="string">'label'</span>].values[:<span class="number">10000</span>])</span><br><span class="line"></span><br><span class="line">val_pred = clf.predict(train_test[<span class="number">10000</span>:])</span><br><span class="line">print(f1_score(train_df[<span class="string">'label'</span>].values[<span class="number">10000</span>:], val_pred, average=<span class="string">'macro'</span>))</span><br></pre></td></tr></table></figure>
<p><strong>output</strong>: 0.7410794074418383</p>
<h2 id="2-TF-IDF-RidgeClassifier"><a href="#2-TF-IDF-RidgeClassifier" class="headerlink" title="2. TF-IDF + RidgeClassifier"></a>2. TF-IDF + RidgeClassifier</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.feature_extraction.text <span class="keyword">import</span> TfidfVectorizer</span><br><span class="line"></span><br><span class="line">train_df = pd.read_csv(<span class="string">'/kaggle/input/newsclassestestdata/train_set.csv/train_set.csv'</span>, sep=<span class="string">'\t'</span>, nrows=<span class="number">15000</span>)</span><br><span class="line">tfidf = TfidfVectorizer(ngram_range=(<span class="number">1</span>,<span class="number">3</span>), max_features=<span class="number">3000</span>)</span><br><span class="line">train_test = tfidf.fit_transform(train_df[<span class="string">'text'</span>])</span><br><span class="line">clf = RidgeClassifier()</span><br><span class="line">clf.fit(train_test[:<span class="number">10000</span>], train_df[<span class="string">'label'</span>].values[:<span class="number">10000</span>])</span><br><span class="line"></span><br><span class="line">val_pred = clf.predict(train_test[<span class="number">10000</span>:])</span><br><span class="line">print(f1_score(train_df[<span class="string">'label'</span>].values[<span class="number">10000</span>:], val_pred, average=<span class="string">'macro'</span>))</span><br></pre></td></tr></table></figure>
<p><strong>output</strong>: 0.8721598830546126</p>
<p>Try a bigger max_features:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">tfid_try = TfidfVectorizer(ngram_range=(<span class="number">1</span>, <span class="number">3</span>), max_features=<span class="number">5000</span>)</span><br><span class="line">train_try = tfid_try.fit_transform(train_df[<span class="string">'text'</span>])</span><br><span class="line">clf_try = RidgeClassifier()</span><br><span class="line">clf_try.fit(train_try[:<span class="number">10000</span>], train_df[<span class="string">'label'</span>].values[:<span class="number">10000</span>])</span><br><span class="line">val_pred_try = clf_try.predict(train_try[<span class="number">10000</span>:])</span><br><span class="line">print(f1_score(train_df[<span class="string">'label'</span>].values[<span class="number">10000</span>:], val_pred_try, average=<span class="string">'macro'</span>))</span><br></pre></td></tr></table></figure>
<p><strong>output</strong>: 0.8850817067811825</p>
<h2 id="3-LogisticRegression"><a href="#3-LogisticRegression" class="headerlink" title="3. LogisticRegression"></a>3. LogisticRegression</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> linear_model</span><br><span class="line"></span><br><span class="line">tfidf = TfidfVectorizer(ngram_range=(<span class="number">1</span>,<span class="number">3</span>), max_features=<span class="number">5000</span>)</span><br><span class="line">train_test = tfidf.fit_transform(train_df[<span class="string">'text'</span>])</span><br><span class="line"></span><br><span class="line">reg = linear_model.LogisticRegression(penalty=<span class="string">'l2'</span>, C=<span class="number">1.0</span>, solver=<span class="string">'liblinear'</span>)</span><br><span class="line">reg.fit(train_test[:<span class="number">10000</span>], train_df[<span class="string">'label'</span>].values[:<span class="number">10000</span>])</span><br><span class="line"></span><br><span class="line">val_pred = reg.predict(train_test[<span class="number">10000</span>:])</span><br><span class="line">print(f1_score(train_df[<span class="string">'label'</span>].values[<span class="number">10000</span>:], val_pred, average=<span class="string">'macro'</span>))</span><br></pre></td></tr></table></figure>
<p><strong>output</strong>: 0.8464704900433653</p>
<h2 id="4-SGDClassifier"><a href="#4-SGDClassifier" class="headerlink" title="4. SGDClassifier"></a>4. SGDClassifier</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">tfidf = TfidfVectorizer(ngram_range=(<span class="number">1</span>,<span class="number">3</span>), max_features=<span class="number">5000</span>)</span><br><span class="line">train_test = tfidf.fit_transform(train_df[<span class="string">'text'</span>])</span><br><span class="line"></span><br><span class="line">reg = linear_model.SGDClassifier(loss=<span class="string">"log"</span>, penalty=<span class="string">'l2'</span>, alpha=<span class="number">0.0001</span>,l1_ratio=<span class="number">0.15</span>) </span><br><span class="line">reg.fit(train_test[:<span class="number">10000</span>], train_df[<span class="string">'label'</span>].values[:<span class="number">10000</span>])</span><br><span class="line"></span><br><span class="line">val_pred = reg.predict(train_test[<span class="number">10000</span>:])</span><br><span class="line">print(f1_score(train_df[<span class="string">'label'</span>].values[<span class="number">10000</span>:], val_pred, average=<span class="string">'macro'</span>))</span><br></pre></td></tr></table></figure>
<p><strong>output</strong>: 0.8461511856339045</p>
<h2 id="5-SVM"><a href="#5-SVM" class="headerlink" title="5. SVM"></a>5. SVM</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> svm</span><br><span class="line">tfidf = TfidfVectorizer(ngram_range=(<span class="number">1</span>,<span class="number">3</span>), max_features=<span class="number">5000</span>)</span><br><span class="line">train_test = tfidf.fit_transform(train_df[<span class="string">'text'</span>])</span><br><span class="line"></span><br><span class="line">reg = svm.SVC(C=<span class="number">1.0</span>, kernel=<span class="string">'linear'</span>, degree=<span class="number">3</span>, gamma=<span class="string">'auto'</span>,decision_function_shape=<span class="string">'ovr'</span>)</span><br><span class="line">reg.fit(train_test[:<span class="number">10000</span>], train_df[<span class="string">'label'</span>].values[:<span class="number">10000</span>])</span><br><span class="line"></span><br><span class="line">val_pred = reg.predict(train_test[<span class="number">10000</span>:])</span><br><span class="line">print(f1_score(train_df[<span class="string">'label'</span>].values[<span class="number">10000</span>:], val_pred, average=<span class="string">'macro'</span>))</span><br></pre></td></tr></table></figure>
<p><strong>output</strong>: 0.883129115819089</p>
<h2 id="6-Summary"><a href="#6-Summary" class="headerlink" title="6. Summary"></a>6. Summary</h2><div class="table-container">
<table>
<thead>
<tr>
<th>method</th>
<th>f1_score</th>
</tr>
</thead>
<tbody>
<tr>
<td>Count Vectors + RidgeClassifier</td>
<td>0.7410794074418383</td>
</tr>
<tr>
<td>TF-IDF + RidgeClassifier</td>
<td><strong>0.8850817067811825</strong></td>
</tr>
<tr>
<td>TF-IDF + LogisticRegression</td>
<td>0.8464704900433653</td>
</tr>
<tr>
<td>TF-IDF + SGDClassifier</td>
<td>0.8461511856339045</td>
</tr>
<tr>
<td>TF-IDF + SVM</td>
<td><strong>0.883129115819089</strong></td>
</tr>
</tbody>
</table>
</div>
]]></content>
      <categories>
        <category>入门</category>
        <category>NLP</category>
        <category>classification</category>
      </categories>
      <tags>
        <tag>NLP</tag>
      </tags>
  </entry>
</search>
